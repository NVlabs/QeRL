2025-10-06 05:50:43.209 | INFO     | llmcompressor.metrics.logger:_create_default_logger:357 - Logging all LLM Compressor modifier-level logs to sparse_logs/06-10-2025_05.50.43.log
2025-10-06 05:50:43.211 | DEBUG    | llmcompressor.core.lifecycle:initialize:92 - Initializing compression lifecycle
2025-10-06 05:50:43.211 | INFO     | llmcompressor.recipe.recipe:from_modifiers:68 - Creating recipe from modifiers
2025-10-06 05:50:43.301 | DEBUG    | llmcompressor.core.lifecycle:initialize:105 - Initialized modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=False ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:50:43.301 | INFO     | llmcompressor.core.lifecycle:initialize:110 - Compression lifecycle initialized for 1 modifiers
2025-10-06 05:50:43.301 | INFO     | llmcompressor.pipelines.independent.pipeline:IndependentPipeline:43 - Inferred `SequentialPipeline` for `GPTQModifier`
2025-10-06 05:50:45.106 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:50:45.106 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(kwargs, labels, logits, loss):
    if labels is not None:
        loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
    return (loss,)
2025-10-06 05:50:45.106 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:50:45.109 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:50:45.109 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(input_ids, inputs_embeds):
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError('You must specify exactly one of input_ids or inputs_embeds')
    return ()
2025-10-06 05:50:45.109 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:50:45.109 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:50:45.109 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_1(input_ids, inputs_embeds):
    if inputs_embeds is None:
        inputs_embeds: torch.Tensor = self.embed_tokens(input_ids)
    return (inputs_embeds,)
2025-10-06 05:50:45.109 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:50:45.109 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:50:45.110 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_2(past_key_values, use_cache):
    if use_cache and past_key_values is None:
        past_key_values = DynamicCache(config=self.config)
    return (past_key_values,)
2025-10-06 05:50:45.110 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:50:45.110 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:50:45.110 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_3(cache_position, inputs_embeds, past_key_values, *, past_seen_tokens=None):
    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position: torch.Tensor = torch.arange(past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device)
    return (cache_position, past_seen_tokens)
2025-10-06 05:50:45.110 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:50:45.110 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:50:45.110 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_4(cache_position, position_ids):
    if position_ids is None:
        position_ids = cache_position.unsqueeze(0)
    return (position_ids,)
2025-10-06 05:50:45.110 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:50:45.111 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:50:45.111 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_5(attention_mask, cache_position, inputs_embeds, past_key_values, position_ids):
    return create_causal_mask(config=self.config, input_embeds=inputs_embeds, attention_mask=attention_mask, cache_position=cache_position, past_key_values=past_key_values, position_ids=position_ids)
    return ()
2025-10-06 05:50:45.111 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:50:45.269 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_START
2025-10-06 05:50:45.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aec800>
2025-10-06 05:50:45.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c180170>
2025-10-06 05:50:45.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aec950>
2025-10-06 05:50:45.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aed7f0>
2025-10-06 05:50:45.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aed700>
2025-10-06 05:50:45.280 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aed610>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aed790>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aedaf0>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aedbb0>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aedc40>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aedd00>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aeddc0>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aedcd0>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aede50>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aee150>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aee1e0>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aee0f0>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aee1b0>
2025-10-06 05:50:45.281 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aee510>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aee5a0>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aee660>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aee420>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aee840>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aee930>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aba6f0>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187a497f0>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1490>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aeff50>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1580>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1640>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1700>
2025-10-06 05:50:45.282 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c17f0>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c18e0>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1910>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c19d0>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1a90>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1a60>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1be0>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1ca0>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1d30>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1e20>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1f10>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c1e80>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2030>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2120>
2025-10-06 05:50:45.283 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2090>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2180>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2330>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2420>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c24e0>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c25d0>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2690>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2750>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2840>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2900>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c29c0>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2a80>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2b40>
2025-10-06 05:50:45.284 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2c00>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2c90>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2d80>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2e40>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2f00>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c2ff0>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c30e0>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c31d0>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3290>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3350>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3440>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c34d0>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3590>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3470>
2025-10-06 05:50:45.285 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3620>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c37d0>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c36e0>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3920>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3860>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3b00>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3aa0>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3c50>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3d40>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3e30>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3f20>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c1c3fb0>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138140>
2025-10-06 05:50:45.286 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138230>
2025-10-06 05:50:45.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138320>
2025-10-06 05:50:45.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138380>
2025-10-06 05:50:45.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138440>
2025-10-06 05:50:45.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138350>
2025-10-06 05:50:45.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441385c0>
2025-10-06 05:50:45.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138680>
2025-10-06 05:50:45.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138740>
2025-10-06 05:50:45.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441386e0>
2025-10-06 05:50:45.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514c19cbf0>
2025-10-06 05:50:45.287 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138950>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138a40>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138b30>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138c20>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138ce0>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138da0>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138e60>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138f50>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139010>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139100>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441391f0>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441392b0>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139370>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139250>
2025-10-06 05:50:45.288 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441394f0>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139310>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139670>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139760>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139730>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441398b0>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441399a0>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139a90>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139b50>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139c40>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139be0>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139d90>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139ca0>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144139e20>
2025-10-06 05:50:45.289 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a000>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a0c0>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a1b0>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a270>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a150>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a420>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a4e0>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a5a0>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a660>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144138dd0>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a810>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a720>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413a9c0>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413aab0>
2025-10-06 05:50:45.290 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187aefd70>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413ac00>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413acf0>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413ade0>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413aea0>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413af90>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b050>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b140>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b200>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b2f0>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b1a0>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b470>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b500>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441385f0>
2025-10-06 05:50:45.291 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b6b0>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b7a0>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b860>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413b950>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413ba10>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413bad0>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413bbc0>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413bb30>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413bd10>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413bc20>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413bec0>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413bcb0>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15514413bf20>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154140>
2025-10-06 05:50:45.292 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154200>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441542f0>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441543b0>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154470>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154440>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441545c0>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154500>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154770>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154860>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154800>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441549b0>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154aa0>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154b90>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154c80>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154d70>
2025-10-06 05:50:45.293 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154d40>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154ec0>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144154fb0>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441550a0>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155130>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441551f0>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441552b0>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441553a0>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155460>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155550>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155400>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155520>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155700>
2025-10-06 05:50:45.294 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155610>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441557c0>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155940>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155a30>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155b20>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155c10>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155cd0>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155d90>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155e50>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155dc0>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155fa0>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144155eb0>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156120>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156210>
2025-10-06 05:50:45.295 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441561b0>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156360>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441563f0>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441564e0>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156570>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156600>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156660>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156720>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441567e0>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441568d0>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1551441569c0>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156ab0>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156b70>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156c60>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156d20>
2025-10-06 05:50:45.296 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156de0>
2025-10-06 05:50:45.297 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155144156ed0>
2025-10-06 05:50:45.297 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:50:54.286 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:50:54.287 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.self_attn.q_proj using 256 samples
2025-10-06 05:50:56.381 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 212.46446
2025-10-06 05:50:56.381 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.02530e+00, min=3.42633e-02, max=1.23983e+00
2025-10-06 05:50:56.382 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 2.09s
2025-10-06 05:50:56.382 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 212.46
2025-10-06 05:50:56.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.77% | total memory: 85 GB
2025-10-06 05:50:56.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:56.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:56.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:56.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:56.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:56.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:56.382 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:56.383 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:50:56.383 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.self_attn.k_proj using 256 samples
2025-10-06 05:50:57.824 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 96.06703
2025-10-06 05:50:57.824 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.02530e+00, min=3.42633e-02, max=1.23983e+00
2025-10-06 05:50:57.824 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.44s
2025-10-06 05:50:57.824 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 96.07
2025-10-06 05:50:57.824 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.77% | total memory: 85 GB
2025-10-06 05:50:57.824 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:57.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:57.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:57.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:57.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:57.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:57.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:57.825 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:50:57.826 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.self_attn.v_proj using 256 samples
2025-10-06 05:50:59.130 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2.34151
2025-10-06 05:50:59.131 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.02530e+00, min=3.42633e-02, max=1.23983e+00
2025-10-06 05:50:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:50:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.34
2025-10-06 05:50:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.78% | total memory: 85 GB
2025-10-06 05:50:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:59.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:50:59.132 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:50:59.132 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.self_attn.o_proj using 256 samples
2025-10-06 05:51:00.459 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 0.30274
2025-10-06 05:51:00.459 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.36611e+01, min=8.12981e-01, max=2.10406e+01
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.30
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.78% | total memory: 85 GB
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:00.460 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:51:00.461 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.mlp.gate_proj using 256 samples
2025-10-06 05:51:01.863 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 62.85059
2025-10-06 05:51:01.864 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01158e+00, min=2.02489e-01, max=1.96368e+00
2025-10-06 05:51:01.864 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:51:01.864 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 62.85
2025-10-06 05:51:01.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.78% | total memory: 85 GB
2025-10-06 05:51:01.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:01.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:01.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:01.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:01.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:01.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:01.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:01.865 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:51:01.866 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.mlp.up_proj using 256 samples
2025-10-06 05:51:03.266 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 53.65304
2025-10-06 05:51:03.267 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01158e+00, min=2.02489e-01, max=1.96368e+00
2025-10-06 05:51:03.267 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:51:03.267 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 53.65
2025-10-06 05:51:03.267 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.78% | total memory: 85 GB
2025-10-06 05:51:03.267 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:03.267 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:03.268 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:03.268 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:03.268 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:03.268 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:03.268 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:03.268 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:51:03.269 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.mlp.down_proj using 256 samples
2025-10-06 05:51:08.113 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1.08358
2025-10-06 05:51:08.116 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.17279e+01, min=1.64067e-01, max=1.56044e+01
2025-10-06 05:51:08.116 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.85s
2025-10-06 05:51:08.116 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.08
2025-10-06 05:51:08.116 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 8.70% | total memory: 85 GB
2025-10-06 05:51:08.116 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:08.116 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:08.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:08.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:08.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:08.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:08.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:08.117 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:51:08.118 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:51:19.877 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:51:19.877 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.self_attn.q_proj using 256 samples
2025-10-06 05:51:21.234 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 234.40353
2025-10-06 05:51:21.235 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.33570e-01, min=2.97579e-02, max=8.01346e-01
2025-10-06 05:51:21.235 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:51:21.235 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 234.40
2025-10-06 05:51:21.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:51:21.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:21.236 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:21.236 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:21.236 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:21.236 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:21.236 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:21.236 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:21.236 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:51:21.237 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.self_attn.k_proj using 256 samples
2025-10-06 05:51:22.541 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 126.55855
2025-10-06 05:51:22.542 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.33570e-01, min=2.97579e-02, max=8.01346e-01
2025-10-06 05:51:22.542 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:51:22.542 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 126.56
2025-10-06 05:51:22.542 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:51:22.542 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:22.543 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:22.543 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:22.543 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:22.543 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:22.543 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:22.543 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:22.543 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:51:22.544 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.self_attn.v_proj using 256 samples
2025-10-06 05:51:23.847 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 7.83038
2025-10-06 05:51:23.847 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.33570e-01, min=2.97579e-02, max=8.01346e-01
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7.83
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:23.848 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:51:23.849 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.self_attn.o_proj using 256 samples
2025-10-06 05:51:25.179 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 0.22806
2025-10-06 05:51:25.179 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01139e+01, min=1.25992e+00, max=2.14835e+01
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.23
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:25.180 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:51:25.181 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.mlp.gate_proj using 256 samples
2025-10-06 05:51:26.591 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 164.47824
2025-10-06 05:51:26.592 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.14100e-01, min=1.61563e-01, max=1.23142e+00
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 164.48
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:26.593 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:51:26.594 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.mlp.up_proj using 256 samples
2025-10-06 05:51:28.001 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 142.14102
2025-10-06 05:51:28.002 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.14100e-01, min=1.61563e-01, max=1.23142e+00
2025-10-06 05:51:28.002 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:51:28.002 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 142.14
2025-10-06 05:51:28.002 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:51:28.002 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:28.002 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:28.002 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:28.003 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:28.003 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:28.003 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:28.003 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:28.003 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:51:28.004 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.mlp.down_proj using 256 samples
2025-10-06 05:51:32.866 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1211.02478
2025-10-06 05:51:32.868 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.91123e-01, min=5.23227e-03, max=8.99909e-01
2025-10-06 05:51:32.868 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.86s
2025-10-06 05:51:32.869 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1211.02
2025-10-06 05:51:32.869 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.47% | total memory: 85 GB
2025-10-06 05:51:32.869 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:32.869 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:32.869 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:32.869 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:32.869 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:32.869 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:32.869 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:32.869 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:51:32.870 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:51:43.695 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:51:43.696 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.self_attn.q_proj using 256 samples
2025-10-06 05:51:45.052 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 626.56708
2025-10-06 05:51:45.053 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.14030e-01, min=2.52494e-02, max=6.44837e-01
2025-10-06 05:51:45.053 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:51:45.053 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 626.57
2025-10-06 05:51:45.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:51:45.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:45.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:45.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:45.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:45.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:45.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:45.053 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:45.054 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:51:45.054 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.self_attn.k_proj using 256 samples
2025-10-06 05:51:46.357 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 375.54492
2025-10-06 05:51:46.358 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.14030e-01, min=2.52494e-02, max=6.44837e-01
2025-10-06 05:51:46.358 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:51:46.358 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 375.54
2025-10-06 05:51:46.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:51:46.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:46.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:46.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:46.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:46.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:46.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:46.359 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:46.359 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:51:46.360 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.self_attn.v_proj using 256 samples
2025-10-06 05:51:47.662 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 22.92592
2025-10-06 05:51:47.663 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.14030e-01, min=2.52494e-02, max=6.44837e-01
2025-10-06 05:51:47.663 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:51:47.663 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 22.93
2025-10-06 05:51:47.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:51:47.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:47.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:47.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:47.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:47.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:47.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:47.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:47.664 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:51:47.665 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.self_attn.o_proj using 256 samples
2025-10-06 05:51:48.993 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1.68867
2025-10-06 05:51:48.994 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.33954e+00, min=2.11811e-01, max=3.09108e+00
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.69
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:48.994 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:51:48.995 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.mlp.gate_proj using 256 samples
2025-10-06 05:51:50.400 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 385.20358
2025-10-06 05:51:50.401 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.31845e-01, min=1.80396e-02, max=1.10649e+00
2025-10-06 05:51:50.401 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:51:50.401 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 385.20
2025-10-06 05:51:50.402 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:51:50.402 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:50.402 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:50.402 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:50.402 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:50.402 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:50.402 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:50.402 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:50.402 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:51:50.403 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.mlp.up_proj using 256 samples
2025-10-06 05:51:51.808 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 309.38843
2025-10-06 05:51:51.809 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.31845e-01, min=1.80396e-02, max=1.10649e+00
2025-10-06 05:51:51.809 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:51:51.810 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 309.39
2025-10-06 05:51:51.810 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:51:51.810 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:51.810 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:51.810 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:51.810 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:51.810 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:51.810 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:51.810 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:51.810 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:51:51.811 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.mlp.down_proj using 256 samples
2025-10-06 05:51:56.664 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1.96599
2025-10-06 05:51:56.667 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.66831e+00, min=4.45464e-01, max=8.51882e+00
2025-10-06 05:51:56.667 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.86s
2025-10-06 05:51:56.667 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.97
2025-10-06 05:51:56.667 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.47% | total memory: 85 GB
2025-10-06 05:51:56.667 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:56.667 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:56.667 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:56.667 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:56.668 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:56.668 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:56.668 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:51:56.668 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:51:56.669 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:52:06.508 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:52:06.508 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.self_attn.q_proj using 256 samples
2025-10-06 05:52:07.919 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 747.38074
2025-10-06 05:52:07.919 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.32583e-01, min=2.61994e-02, max=5.79172e-01
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 747.38
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:07.920 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:52:07.921 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.self_attn.k_proj using 256 samples
2025-10-06 05:52:09.229 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 407.15509
2025-10-06 05:52:09.230 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.32583e-01, min=2.61994e-02, max=5.79172e-01
2025-10-06 05:52:09.230 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:52:09.230 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 407.16
2025-10-06 05:52:09.231 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:09.231 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:09.231 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:09.231 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:09.231 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:09.231 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:09.231 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:09.231 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:09.231 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:52:09.232 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.self_attn.v_proj using 256 samples
2025-10-06 05:52:10.536 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 40.71936
2025-10-06 05:52:10.537 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.32583e-01, min=2.61994e-02, max=5.79172e-01
2025-10-06 05:52:10.537 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:52:10.537 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 40.72
2025-10-06 05:52:10.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:10.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:10.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:10.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:10.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:10.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:10.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:10.538 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:10.538 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:52:10.539 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.self_attn.o_proj using 256 samples
2025-10-06 05:52:11.869 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1.05657
2025-10-06 05:52:11.870 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.58626e+00, min=2.90996e-01, max=7.49127e+00
2025-10-06 05:52:11.870 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:52:11.870 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.06
2025-10-06 05:52:11.870 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:11.870 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:11.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:11.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:11.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:11.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:11.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:11.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:11.871 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:52:11.872 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.mlp.gate_proj using 256 samples
2025-10-06 05:52:13.272 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 669.83203
2025-10-06 05:52:13.273 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.30174e-01, min=1.94965e-02, max=8.98302e-01
2025-10-06 05:52:13.273 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:52:13.273 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 669.83
2025-10-06 05:52:13.273 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:13.273 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:13.273 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:13.273 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:13.273 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:13.274 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:13.274 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:13.274 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:13.274 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:52:13.275 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.mlp.up_proj using 256 samples
2025-10-06 05:52:14.673 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 487.19360
2025-10-06 05:52:14.674 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.30174e-01, min=1.94965e-02, max=8.98302e-01
2025-10-06 05:52:14.674 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:52:14.674 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 487.19
2025-10-06 05:52:14.674 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:14.674 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:14.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:14.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:14.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:14.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:14.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:14.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:14.675 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:52:14.676 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.mlp.down_proj using 256 samples
2025-10-06 05:52:19.552 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4.38435
2025-10-06 05:52:19.555 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.63745e+00, min=2.22567e-01, max=5.83011e+00
2025-10-06 05:52:19.555 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 05:52:19.555 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.38
2025-10-06 05:52:19.555 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.59% | total memory: 85 GB
2025-10-06 05:52:19.555 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:19.556 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:19.556 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:19.556 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:19.556 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:19.556 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:19.556 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:19.556 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:52:19.557 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:52:29.432 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:52:29.432 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.self_attn.q_proj using 256 samples
2025-10-06 05:52:30.792 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 799.78674
2025-10-06 05:52:30.793 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.29285e-01, min=2.08896e-02, max=5.59039e-01
2025-10-06 05:52:30.793 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:52:30.793 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 799.79
2025-10-06 05:52:30.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:52:30.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:30.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:30.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:30.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:30.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:30.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:30.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:30.794 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:52:30.795 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.self_attn.k_proj using 256 samples
2025-10-06 05:52:32.101 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 440.96667
2025-10-06 05:52:32.102 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.29285e-01, min=2.08896e-02, max=5.59039e-01
2025-10-06 05:52:32.102 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:52:32.102 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 440.97
2025-10-06 05:52:32.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:32.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:32.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:32.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:32.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:32.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:32.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:32.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:32.103 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:52:32.103 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.self_attn.v_proj using 256 samples
2025-10-06 05:52:33.403 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 47.61145
2025-10-06 05:52:33.404 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.29285e-01, min=2.08896e-02, max=5.59039e-01
2025-10-06 05:52:33.404 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:52:33.404 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 47.61
2025-10-06 05:52:33.405 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:33.405 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:33.405 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:33.405 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:33.405 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:33.405 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:33.405 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:33.405 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:33.405 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:52:33.406 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.self_attn.o_proj using 256 samples
2025-10-06 05:52:34.729 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2.44925
2025-10-06 05:52:34.730 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.41858e+00, min=4.48771e-01, max=4.74109e+00
2025-10-06 05:52:34.730 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:52:34.730 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.45
2025-10-06 05:52:34.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:34.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:34.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:34.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:34.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:34.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:34.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:34.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:34.731 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:52:34.732 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.mlp.gate_proj using 256 samples
2025-10-06 05:52:36.129 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1111.58081
2025-10-06 05:52:36.130 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.63306e-01, min=1.69354e-02, max=7.63800e-01
2025-10-06 05:52:36.130 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:52:36.130 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1111.58
2025-10-06 05:52:36.130 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:36.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:36.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:36.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:36.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:36.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:36.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:36.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:36.131 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:52:36.132 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.mlp.up_proj using 256 samples
2025-10-06 05:52:37.534 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 718.87439
2025-10-06 05:52:37.535 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.63306e-01, min=1.69354e-02, max=7.63800e-01
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 718.87
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:37.535 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:52:37.536 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.mlp.down_proj using 256 samples
2025-10-06 05:52:42.386 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 8.32729
2025-10-06 05:52:42.389 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.53873e+00, min=3.19396e-01, max=4.19918e+00
2025-10-06 05:52:42.389 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.85s
2025-10-06 05:52:42.389 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8.33
2025-10-06 05:52:42.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.59% | total memory: 85 GB
2025-10-06 05:52:42.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:42.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:42.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:42.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:42.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:42.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:42.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:42.394 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:52:42.395 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:52:52.273 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:52:52.273 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.self_attn.q_proj using 256 samples
2025-10-06 05:52:53.630 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1341.22827
2025-10-06 05:52:53.631 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.79204e-01, min=1.25233e-02, max=3.05512e-01
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1341.23
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:53.632 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:52:53.633 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.self_attn.k_proj using 256 samples
2025-10-06 05:52:54.933 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 762.61188
2025-10-06 05:52:54.934 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.79204e-01, min=1.25233e-02, max=3.05512e-01
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 762.61
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:54.934 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:52:54.935 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.self_attn.v_proj using 256 samples
2025-10-06 05:52:56.233 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 59.17961
2025-10-06 05:52:56.234 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.79204e-01, min=1.25233e-02, max=3.05512e-01
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 59.18
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:56.234 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:52:56.235 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.self_attn.o_proj using 256 samples
2025-10-06 05:52:57.563 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4.42584
2025-10-06 05:52:57.564 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.66165e+00, min=1.53282e-01, max=3.53952e+00
2025-10-06 05:52:57.564 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:52:57.564 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.43
2025-10-06 05:52:57.564 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:57.564 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:57.564 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:57.564 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:57.564 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:57.565 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:57.565 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:57.565 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:57.565 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:52:57.565 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.mlp.gate_proj using 256 samples
2025-10-06 05:52:58.960 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1599.32361
2025-10-06 05:52:58.961 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.18357e-01, min=1.50302e-02, max=6.80043e-01
2025-10-06 05:52:58.961 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:52:58.962 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1599.32
2025-10-06 05:52:58.962 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:52:58.962 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:58.962 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:58.962 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:58.962 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:58.962 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:58.962 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:58.962 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:52:58.962 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:52:58.963 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.mlp.up_proj using 256 samples
2025-10-06 05:53:00.360 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1042.99268
2025-10-06 05:53:00.361 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.18357e-01, min=1.50302e-02, max=6.80043e-01
2025-10-06 05:53:00.361 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:53:00.361 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1042.99
2025-10-06 05:53:00.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:00.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:00.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:00.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:00.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:00.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:00.362 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:00.362 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:00.362 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:53:00.362 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.mlp.down_proj using 256 samples
2025-10-06 05:53:05.214 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 15.92010
2025-10-06 05:53:05.217 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.85133e+00, min=1.27569e-01, max=3.33250e+00
2025-10-06 05:53:05.217 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.85s
2025-10-06 05:53:05.217 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 15.92
2025-10-06 05:53:05.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.59% | total memory: 85 GB
2025-10-06 05:53:05.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:05.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:05.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:05.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:05.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:05.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:05.217 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:05.218 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:53:05.219 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:53:15.100 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:53:15.101 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.self_attn.q_proj using 256 samples
2025-10-06 05:53:16.460 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1561.35681
2025-10-06 05:53:16.461 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.60557e-01, min=1.06567e-02, max=2.89490e-01
2025-10-06 05:53:16.461 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:53:16.461 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1561.36
2025-10-06 05:53:16.462 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:53:16.462 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:16.462 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:16.462 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:16.462 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:16.462 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:16.462 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:16.462 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:16.462 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:53:16.463 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.self_attn.k_proj using 256 samples
2025-10-06 05:53:17.765 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 849.18341
2025-10-06 05:53:17.766 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.60557e-01, min=1.06567e-02, max=2.89490e-01
2025-10-06 05:53:17.766 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:53:17.766 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 849.18
2025-10-06 05:53:17.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:17.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:17.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:17.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:17.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:17.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:17.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:17.767 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:17.767 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:53:17.768 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.self_attn.v_proj using 256 samples
2025-10-06 05:53:19.069 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 76.91798
2025-10-06 05:53:19.070 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.60557e-01, min=1.06567e-02, max=2.89490e-01
2025-10-06 05:53:19.070 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:53:19.070 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 76.92
2025-10-06 05:53:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:19.071 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:53:19.072 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.self_attn.o_proj using 256 samples
2025-10-06 05:53:20.399 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 7.39137
2025-10-06 05:53:20.400 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.27071e+00, min=2.09730e-01, max=2.78980e+00
2025-10-06 05:53:20.400 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:53:20.400 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7.39
2025-10-06 05:53:20.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:20.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:20.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:20.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:20.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:20.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:20.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:20.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:20.403 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:53:20.404 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.mlp.gate_proj using 256 samples
2025-10-06 05:53:21.807 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2110.73462
2025-10-06 05:53:21.808 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.90230e-01, min=1.39089e-02, max=6.17683e-01
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2110.73
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:21.809 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:53:21.810 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.mlp.up_proj using 256 samples
2025-10-06 05:53:23.215 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1363.64380
2025-10-06 05:53:23.216 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.90230e-01, min=1.39089e-02, max=6.17683e-01
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1363.64
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:23.216 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:53:23.217 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.mlp.down_proj using 256 samples
2025-10-06 05:53:28.085 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 24.31689
2025-10-06 05:53:28.088 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.46601e+00, min=2.97964e-01, max=2.47484e+00
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 24.32
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.59% | total memory: 85 GB
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:28.088 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:53:28.089 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:53:37.868 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:53:37.868 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.self_attn.q_proj using 256 samples
2025-10-06 05:53:39.229 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1694.18774
2025-10-06 05:53:39.230 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.44137e-01, min=1.19523e-02, max=2.72675e-01
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1694.19
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:39.230 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:53:39.231 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.self_attn.k_proj using 256 samples
2025-10-06 05:53:40.533 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 997.45587
2025-10-06 05:53:40.534 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.44137e-01, min=1.19523e-02, max=2.72675e-01
2025-10-06 05:53:40.534 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:53:40.534 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 997.46
2025-10-06 05:53:40.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:40.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:40.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:40.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:40.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:40.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:40.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:40.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:40.535 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:53:40.535 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.self_attn.v_proj using 256 samples
2025-10-06 05:53:41.837 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 88.60263
2025-10-06 05:53:41.838 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.44137e-01, min=1.19523e-02, max=2.72675e-01
2025-10-06 05:53:41.838 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:53:41.838 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 88.60
2025-10-06 05:53:41.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:41.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:41.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:41.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:41.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:41.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:41.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:41.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:41.842 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:53:41.842 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.self_attn.o_proj using 256 samples
2025-10-06 05:53:43.173 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 11.21721
2025-10-06 05:53:43.174 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.03049e+00, min=1.56948e-01, max=1.83224e+00
2025-10-06 05:53:43.174 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:53:43.174 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11.22
2025-10-06 05:53:43.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:43.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:43.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:43.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:43.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:43.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:43.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:43.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:43.175 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:53:43.176 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.mlp.gate_proj using 256 samples
2025-10-06 05:53:44.572 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2395.68408
2025-10-06 05:53:44.573 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.74552e-01, min=1.53371e-02, max=4.07009e-01
2025-10-06 05:53:44.573 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:53:44.573 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2395.68
2025-10-06 05:53:44.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:44.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:44.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:44.574 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:44.574 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:44.574 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:44.574 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:44.574 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:44.574 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:53:44.575 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.mlp.up_proj using 256 samples
2025-10-06 05:53:45.966 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1633.87268
2025-10-06 05:53:45.967 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.74552e-01, min=1.53371e-02, max=4.07009e-01
2025-10-06 05:53:45.967 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.39s
2025-10-06 05:53:45.967 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1633.87
2025-10-06 05:53:45.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:53:45.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:45.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:45.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:45.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:45.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:45.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:45.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:45.968 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:53:45.969 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.mlp.down_proj using 256 samples
2025-10-06 05:53:50.811 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 33.77927
2025-10-06 05:53:50.814 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.25884e+00, min=1.52805e-01, max=2.28448e+00
2025-10-06 05:53:50.814 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.85s
2025-10-06 05:53:50.814 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 33.78
2025-10-06 05:53:50.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:53:50.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:50.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:50.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:50.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:50.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:50.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:50.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:53:50.816 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:53:50.817 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:54:00.595 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:54:00.595 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.self_attn.q_proj using 256 samples
2025-10-06 05:54:01.955 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2201.56494
2025-10-06 05:54:01.956 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.26440e-01, min=1.64905e-02, max=2.35540e-01
2025-10-06 05:54:01.956 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:54:01.956 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2201.56
2025-10-06 05:54:01.956 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:54:01.956 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:01.956 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:01.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:01.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:01.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:01.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:01.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:01.957 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:54:01.958 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.self_attn.k_proj using 256 samples
2025-10-06 05:54:03.261 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1252.65552
2025-10-06 05:54:03.262 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.26440e-01, min=1.64905e-02, max=2.35540e-01
2025-10-06 05:54:03.262 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:54:03.262 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1252.66
2025-10-06 05:54:03.262 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:03.262 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:03.262 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:03.262 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:03.262 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:03.263 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:03.263 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:03.263 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:03.263 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:54:03.263 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.self_attn.v_proj using 256 samples
2025-10-06 05:54:04.566 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 125.33746
2025-10-06 05:54:04.566 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.26440e-01, min=1.64905e-02, max=2.35540e-01
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 125.34
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:04.567 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:54:04.568 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.self_attn.o_proj using 256 samples
2025-10-06 05:54:05.901 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 18.60346
2025-10-06 05:54:05.902 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.52772e-01, min=6.91036e-02, max=1.63018e+00
2025-10-06 05:54:05.902 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:54:05.902 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 18.60
2025-10-06 05:54:05.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:05.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:05.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:05.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:05.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:05.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:05.903 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:05.903 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:05.903 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:54:05.903 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.mlp.gate_proj using 256 samples
2025-10-06 05:54:07.306 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2869.06641
2025-10-06 05:54:07.307 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.60605e-01, min=1.45419e-02, max=5.73414e-01
2025-10-06 05:54:07.307 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:54:07.307 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2869.07
2025-10-06 05:54:07.307 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:07.307 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:07.307 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:07.308 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:07.308 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:07.308 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:07.308 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:07.308 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:07.308 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:54:07.309 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.mlp.up_proj using 256 samples
2025-10-06 05:54:08.708 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1943.31055
2025-10-06 05:54:08.709 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.60605e-01, min=1.45419e-02, max=5.73414e-01
2025-10-06 05:54:08.709 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:54:08.709 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1943.31
2025-10-06 05:54:08.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:08.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:08.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:08.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:08.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:08.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:08.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:08.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:08.710 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:54:08.711 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.mlp.down_proj using 256 samples
2025-10-06 05:54:13.582 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 42.38561
2025-10-06 05:54:13.585 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.12192e+00, min=2.53402e-01, max=1.89115e+00
2025-10-06 05:54:13.585 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:54:13.585 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 42.39
2025-10-06 05:54:13.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:54:13.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:13.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:13.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:13.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:13.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:13.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:13.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:13.586 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:54:13.587 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:54:23.934 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:54:23.935 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.self_attn.q_proj using 256 samples
2025-10-06 05:54:25.296 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2456.78638
2025-10-06 05:54:25.297 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.19453e-01, min=1.49607e-02, max=2.08288e-01
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2456.79
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:25.298 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:54:25.299 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.self_attn.k_proj using 256 samples
2025-10-06 05:54:26.605 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1388.32312
2025-10-06 05:54:26.606 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.19453e-01, min=1.49607e-02, max=2.08288e-01
2025-10-06 05:54:26.606 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:54:26.606 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1388.32
2025-10-06 05:54:26.606 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:26.606 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:26.606 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:26.607 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:26.607 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:26.607 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:26.607 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:26.607 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:26.607 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:54:26.608 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.self_attn.v_proj using 256 samples
2025-10-06 05:54:27.913 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 177.81619
2025-10-06 05:54:27.914 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.19453e-01, min=1.49607e-02, max=2.08288e-01
2025-10-06 05:54:27.914 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:54:27.914 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 177.82
2025-10-06 05:54:27.914 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:27.915 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:27.915 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:27.915 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:27.915 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:27.915 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:27.915 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:27.915 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:27.915 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:54:27.916 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.self_attn.o_proj using 256 samples
2025-10-06 05:54:29.244 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 23.95984
2025-10-06 05:54:29.245 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.13605e-01, min=5.68218e-02, max=2.02008e+00
2025-10-06 05:54:29.245 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:54:29.246 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 23.96
2025-10-06 05:54:29.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:29.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:29.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:29.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:29.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:29.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:29.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:29.246 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:29.246 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:54:29.247 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.mlp.gate_proj using 256 samples
2025-10-06 05:54:30.645 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3306.76416
2025-10-06 05:54:30.646 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.51616e-01, min=1.42105e-02, max=3.87150e-01
2025-10-06 05:54:30.646 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:54:30.646 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3306.76
2025-10-06 05:54:30.646 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:30.646 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:30.646 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:30.646 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:30.647 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:30.647 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:30.647 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:30.647 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:30.647 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:54:30.648 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.mlp.up_proj using 256 samples
2025-10-06 05:54:32.048 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2232.16602
2025-10-06 05:54:32.049 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.51616e-01, min=1.42105e-02, max=3.87150e-01
2025-10-06 05:54:32.049 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:54:32.049 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2232.17
2025-10-06 05:54:32.049 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:32.049 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:32.050 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:32.050 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:32.050 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:32.050 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:32.050 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:32.050 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:32.050 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:54:32.051 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.mlp.down_proj using 256 samples
2025-10-06 05:54:36.922 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 51.84719
2025-10-06 05:54:36.924 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.02475e+00, min=1.30809e-01, max=1.76638e+00
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 51.85
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:36.925 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:54:36.926 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:54:46.630 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:54:46.630 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.self_attn.q_proj using 256 samples
2025-10-06 05:54:47.988 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2980.19849
2025-10-06 05:54:47.989 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.10629e-01, min=1.38085e-02, max=2.14549e-01
2025-10-06 05:54:47.989 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:54:47.989 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2980.20
2025-10-06 05:54:47.989 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:54:47.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:47.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:47.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:47.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:47.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:47.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:47.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:47.990 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:54:47.991 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.self_attn.k_proj using 256 samples
2025-10-06 05:54:49.296 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1661.91663
2025-10-06 05:54:49.297 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.10629e-01, min=1.38085e-02, max=2.14549e-01
2025-10-06 05:54:49.297 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:54:49.297 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1661.92
2025-10-06 05:54:49.297 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:49.297 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:49.297 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:49.297 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:49.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:49.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:49.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:49.298 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:49.298 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:54:49.299 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.self_attn.v_proj using 256 samples
2025-10-06 05:54:50.601 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 165.26555
2025-10-06 05:54:50.602 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.10629e-01, min=1.38085e-02, max=2.14549e-01
2025-10-06 05:54:50.602 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:54:50.602 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 165.27
2025-10-06 05:54:50.602 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:50.602 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:50.602 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:50.602 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:50.602 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:50.602 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:50.602 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:50.602 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:50.603 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:54:50.603 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.self_attn.o_proj using 256 samples
2025-10-06 05:54:51.933 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 24.17118
2025-10-06 05:54:51.934 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.47325e-01, min=5.89447e-02, max=1.59866e+00
2025-10-06 05:54:51.934 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:54:51.934 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 24.17
2025-10-06 05:54:51.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:51.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:51.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:51.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:51.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:51.935 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:51.935 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:51.935 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:51.935 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:54:51.935 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.mlp.gate_proj using 256 samples
2025-10-06 05:54:53.332 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3553.61377
2025-10-06 05:54:53.333 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.43627e-01, min=1.51663e-02, max=3.90067e-01
2025-10-06 05:54:53.333 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:54:53.333 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3553.61
2025-10-06 05:54:53.333 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:53.333 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:53.333 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:53.333 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:53.333 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:53.333 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:53.333 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:53.334 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:53.334 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:54:53.334 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.mlp.up_proj using 256 samples
2025-10-06 05:54:54.738 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2565.91016
2025-10-06 05:54:54.739 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.43627e-01, min=1.51663e-02, max=3.90067e-01
2025-10-06 05:54:54.739 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:54:54.740 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2565.91
2025-10-06 05:54:54.740 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:54:54.740 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:54.740 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:54.740 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:54.740 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:54.740 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:54.740 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:54.740 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:54.740 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:54:54.741 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.mlp.down_proj using 256 samples
2025-10-06 05:54:59.600 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 64.16283
2025-10-06 05:54:59.603 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.36157e-01, min=4.57011e-02, max=1.54479e+00
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.86s
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 64.16
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:54:59.603 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:54:59.604 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:55:09.399 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:55:09.400 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.self_attn.q_proj using 256 samples
2025-10-06 05:55:10.762 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2977.00293
2025-10-06 05:55:10.762 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.04595e-01, min=1.33908e-02, max=1.96831e-01
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2977.00
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:10.763 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:55:10.764 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.self_attn.k_proj using 256 samples
2025-10-06 05:55:12.071 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1764.40625
2025-10-06 05:55:12.071 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.04595e-01, min=1.33908e-02, max=1.96831e-01
2025-10-06 05:55:12.071 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:55:12.072 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1764.41
2025-10-06 05:55:12.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:12.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:12.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:12.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:12.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:12.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:12.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:12.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:12.072 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:55:12.073 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.self_attn.v_proj using 256 samples
2025-10-06 05:55:13.377 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 180.40636
2025-10-06 05:55:13.377 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.04595e-01, min=1.33908e-02, max=1.96831e-01
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 180.41
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:13.378 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:55:13.379 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.self_attn.o_proj using 256 samples
2025-10-06 05:55:14.712 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 27.69379
2025-10-06 05:55:14.713 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.04821e-01, min=1.28092e-01, max=1.37154e+00
2025-10-06 05:55:14.713 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:55:14.713 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 27.69
2025-10-06 05:55:14.715 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:14.715 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:14.715 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:14.715 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:14.715 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:14.715 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:14.715 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:14.715 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:14.716 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:55:14.716 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.mlp.gate_proj using 256 samples
2025-10-06 05:55:16.116 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3912.04199
2025-10-06 05:55:16.117 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.34741e-01, min=1.55140e-02, max=3.40308e-01
2025-10-06 05:55:16.117 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:55:16.117 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3912.04
2025-10-06 05:55:16.121 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:16.121 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:16.121 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:16.121 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:16.121 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:16.121 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:16.121 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:16.121 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:16.121 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:55:16.122 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.mlp.up_proj using 256 samples
2025-10-06 05:55:17.520 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2919.32104
2025-10-06 05:55:17.521 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.34741e-01, min=1.55140e-02, max=3.40308e-01
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2919.32
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:17.522 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:55:17.523 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.mlp.down_proj using 256 samples
2025-10-06 05:55:22.392 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 77.40160
2025-10-06 05:55:22.395 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.52755e-01, min=5.53393e-02, max=1.42153e+00
2025-10-06 05:55:22.395 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:55:22.395 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 77.40
2025-10-06 05:55:22.395 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:55:22.395 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:22.395 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:22.395 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:22.395 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:22.395 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:22.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:22.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:22.396 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:55:22.396 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:55:32.255 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:55:32.255 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.self_attn.q_proj using 256 samples
2025-10-06 05:55:33.617 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2756.23535
2025-10-06 05:55:33.618 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.09401e-01, min=9.42895e-03, max=2.13668e-01
2025-10-06 05:55:33.618 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:55:33.618 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2756.24
2025-10-06 05:55:33.619 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:55:33.619 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:33.619 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:33.619 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:33.619 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:33.619 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:33.619 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:33.619 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:33.619 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:55:33.620 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.self_attn.k_proj using 256 samples
2025-10-06 05:55:34.925 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1521.34058
2025-10-06 05:55:34.926 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.09401e-01, min=9.42895e-03, max=2.13668e-01
2025-10-06 05:55:34.926 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:55:34.926 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1521.34
2025-10-06 05:55:34.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:34.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:34.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:34.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:34.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:34.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:34.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:34.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:34.927 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:55:34.928 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.self_attn.v_proj using 256 samples
2025-10-06 05:55:36.237 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 221.71957
2025-10-06 05:55:36.237 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.09401e-01, min=9.42895e-03, max=2.13668e-01
2025-10-06 05:55:36.237 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:55:36.237 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 221.72
2025-10-06 05:55:36.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:36.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:36.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:36.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:36.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:36.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:36.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:36.238 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:36.238 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:55:36.239 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.self_attn.o_proj using 256 samples
2025-10-06 05:55:37.572 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 33.95371
2025-10-06 05:55:37.573 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.71309e-01, min=7.02696e-02, max=1.24103e+00
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 33.95
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:37.573 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:55:37.574 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.mlp.gate_proj using 256 samples
2025-10-06 05:55:38.981 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3999.83838
2025-10-06 05:55:38.982 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.31304e-01, min=1.39479e-02, max=3.00004e-01
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3999.84
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:38.982 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:55:38.983 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.mlp.up_proj using 256 samples
2025-10-06 05:55:40.389 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3143.37988
2025-10-06 05:55:40.390 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.31304e-01, min=1.39479e-02, max=3.00004e-01
2025-10-06 05:55:40.390 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:55:40.390 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3143.38
2025-10-06 05:55:40.390 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:40.390 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:40.390 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:40.391 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:40.391 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:40.391 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:40.391 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:40.391 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:40.391 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:55:40.392 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.mlp.down_proj using 256 samples
2025-10-06 05:55:45.267 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 82.76787
2025-10-06 05:55:45.270 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.32037e-01, min=9.82902e-02, max=1.40259e+00
2025-10-06 05:55:45.270 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 05:55:45.270 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 82.77
2025-10-06 05:55:45.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:55:45.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:45.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:45.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:45.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:45.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:45.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:45.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:45.293 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:55:45.294 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:55:54.991 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:55:54.991 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.self_attn.q_proj using 256 samples
2025-10-06 05:55:56.356 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3660.52051
2025-10-06 05:55:56.357 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.59296e-02, min=1.30713e-02, max=1.85135e-01
2025-10-06 05:55:56.357 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:55:56.357 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3660.52
2025-10-06 05:55:56.357 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:55:56.357 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:56.357 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:56.357 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:56.357 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:56.358 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:56.358 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:56.358 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:56.358 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:55:56.358 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.self_attn.k_proj using 256 samples
2025-10-06 05:55:57.665 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2130.88672
2025-10-06 05:55:57.666 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.59296e-02, min=1.30713e-02, max=1.85135e-01
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2130.89
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:57.666 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:55:57.667 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.self_attn.v_proj using 256 samples
2025-10-06 05:55:58.971 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 255.40508
2025-10-06 05:55:58.972 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.59296e-02, min=1.30713e-02, max=1.85135e-01
2025-10-06 05:55:58.972 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:55:58.972 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 255.41
2025-10-06 05:55:58.973 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:55:58.973 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:58.973 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:58.973 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:58.973 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:58.973 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:58.973 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:58.973 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:55:58.973 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:55:58.974 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.self_attn.o_proj using 256 samples
2025-10-06 05:56:00.307 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 42.21408
2025-10-06 05:56:00.308 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.74233e-01, min=1.17889e-01, max=1.03842e+00
2025-10-06 05:56:00.308 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:56:00.308 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 42.21
2025-10-06 05:56:00.309 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:00.309 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:00.309 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:00.309 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:00.309 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:00.309 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:00.309 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:00.309 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:00.309 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:56:00.310 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.mlp.gate_proj using 256 samples
2025-10-06 05:56:01.712 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4387.03809
2025-10-06 05:56:01.713 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.25669e-01, min=1.45598e-02, max=3.34893e-01
2025-10-06 05:56:01.713 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:56:01.713 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4387.04
2025-10-06 05:56:01.777 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:01.777 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:01.777 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:01.777 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:01.777 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:01.777 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:01.777 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:01.778 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:01.778 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:56:01.778 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.mlp.up_proj using 256 samples
2025-10-06 05:56:03.175 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3469.91846
2025-10-06 05:56:03.176 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.25669e-01, min=1.45598e-02, max=3.34893e-01
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3469.92
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:03.177 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:56:03.178 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.mlp.down_proj using 256 samples
2025-10-06 05:56:08.054 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 93.66686
2025-10-06 05:56:08.057 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.92215e-01, min=1.37306e-01, max=1.35110e+00
2025-10-06 05:56:08.057 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 05:56:08.057 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 93.67
2025-10-06 05:56:08.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:56:08.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:08.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:08.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:08.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:08.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:08.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:08.058 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:08.058 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:56:08.058 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:56:17.847 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:56:17.847 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.self_attn.q_proj using 256 samples
2025-10-06 05:56:19.215 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3538.97852
2025-10-06 05:56:19.215 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.56353e-02, min=1.25011e-02, max=1.77301e-01
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3538.98
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:19.216 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:56:19.217 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.self_attn.k_proj using 256 samples
2025-10-06 05:56:20.527 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2098.82715
2025-10-06 05:56:20.528 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.56353e-02, min=1.25011e-02, max=1.77301e-01
2025-10-06 05:56:20.528 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:56:20.528 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2098.83
2025-10-06 05:56:20.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:20.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:20.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:20.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:20.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:20.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:20.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:20.529 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:20.529 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:56:20.530 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.self_attn.v_proj using 256 samples
2025-10-06 05:56:21.837 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 254.73497
2025-10-06 05:56:21.837 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.56353e-02, min=1.25011e-02, max=1.77301e-01
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 254.73
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:21.838 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:56:21.839 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.self_attn.o_proj using 256 samples
2025-10-06 05:56:23.173 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 52.87411
2025-10-06 05:56:23.173 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.49147e-01, min=5.21565e-02, max=1.18586e+00
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 52.87
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:23.174 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:56:23.175 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.mlp.gate_proj using 256 samples
2025-10-06 05:56:24.583 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 5190.56445
2025-10-06 05:56:24.584 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.17830e-01, min=1.42933e-02, max=2.90910e-01
2025-10-06 05:56:24.584 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:56:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5190.56
2025-10-06 05:56:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:24.585 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:56:24.586 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.mlp.up_proj using 256 samples
2025-10-06 05:56:25.995 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3925.10889
2025-10-06 05:56:25.996 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.17830e-01, min=1.42933e-02, max=2.90910e-01
2025-10-06 05:56:25.996 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:56:25.997 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3925.11
2025-10-06 05:56:25.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:25.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:25.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:25.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:25.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:25.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:25.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:25.997 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:25.997 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:56:25.998 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.mlp.down_proj using 256 samples
2025-10-06 05:56:30.871 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 123.30994
2025-10-06 05:56:30.873 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.01761e-01, min=7.75786e-02, max=1.40786e+00
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 123.31
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:30.874 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:56:30.875 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:56:40.720 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:56:40.720 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.self_attn.q_proj using 256 samples
2025-10-06 05:56:42.079 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4074.60376
2025-10-06 05:56:42.080 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.69450e-02, min=1.28784e-02, max=1.97785e-01
2025-10-06 05:56:42.080 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:56:42.080 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4074.60
2025-10-06 05:56:42.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:56:42.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:42.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:42.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:42.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:42.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:42.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:42.087 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:42.087 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:56:42.088 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.self_attn.k_proj using 256 samples
2025-10-06 05:56:43.394 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1977.37366
2025-10-06 05:56:43.395 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.69450e-02, min=1.28784e-02, max=1.97785e-01
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1977.37
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:43.396 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:56:43.397 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.self_attn.v_proj using 256 samples
2025-10-06 05:56:44.701 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 284.83276
2025-10-06 05:56:44.703 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.69450e-02, min=1.28784e-02, max=1.97785e-01
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 284.83
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:44.703 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:56:44.705 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.self_attn.o_proj using 256 samples
2025-10-06 05:56:46.037 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 38.86663
2025-10-06 05:56:46.038 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.00147e-01, min=9.04808e-02, max=1.07716e+00
2025-10-06 05:56:46.038 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:56:46.038 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 38.87
2025-10-06 05:56:46.039 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:46.039 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:46.039 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:46.039 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:46.039 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:46.039 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:46.039 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:46.039 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:46.039 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:56:46.040 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.mlp.gate_proj using 256 samples
2025-10-06 05:56:47.442 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 5623.47119
2025-10-06 05:56:47.443 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.15494e-01, min=1.53390e-02, max=3.16748e-01
2025-10-06 05:56:47.443 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:56:47.444 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5623.47
2025-10-06 05:56:47.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:47.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:47.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:47.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:47.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:47.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:47.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:47.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:47.444 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:56:47.445 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.mlp.up_proj using 256 samples
2025-10-06 05:56:48.853 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4045.64111
2025-10-06 05:56:48.854 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.15494e-01, min=1.53390e-02, max=3.16748e-01
2025-10-06 05:56:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:56:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4045.64
2025-10-06 05:56:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:56:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:48.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:48.855 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:56:48.856 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.mlp.down_proj using 256 samples
2025-10-06 05:56:53.728 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 129.74196
2025-10-06 05:56:53.730 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.90700e-01, min=8.66448e-02, max=1.18183e+00
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 129.74
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:56:53.731 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:56:53.732 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:57:03.582 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:57:03.583 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.self_attn.q_proj using 256 samples
2025-10-06 05:57:04.946 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3644.12744
2025-10-06 05:57:04.946 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01022e-01, min=1.19662e-02, max=1.98754e-01
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3644.13
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:04.947 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:57:04.948 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.self_attn.k_proj using 256 samples
2025-10-06 05:57:06.251 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1951.43555
2025-10-06 05:57:06.252 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01022e-01, min=1.19662e-02, max=1.98754e-01
2025-10-06 05:57:06.252 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:57:06.252 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1951.44
2025-10-06 05:57:06.252 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:06.252 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:06.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:06.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:06.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:06.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:06.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:06.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:06.253 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:57:06.254 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.self_attn.v_proj using 256 samples
2025-10-06 05:57:07.556 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 259.84216
2025-10-06 05:57:07.557 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01022e-01, min=1.19662e-02, max=1.98754e-01
2025-10-06 05:57:07.557 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:57:07.557 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 259.84
2025-10-06 05:57:07.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:07.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:07.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:07.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:07.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:07.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:07.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:07.557 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:07.558 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:57:07.558 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.self_attn.o_proj using 256 samples
2025-10-06 05:57:08.887 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 38.89783
2025-10-06 05:57:08.888 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.64319e-01, min=4.98880e-02, max=1.30350e+00
2025-10-06 05:57:08.888 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:57:08.888 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 38.90
2025-10-06 05:57:08.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:08.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:08.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:08.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:08.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:08.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:08.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:08.889 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:08.889 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:57:08.890 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.mlp.gate_proj using 256 samples
2025-10-06 05:57:10.294 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6110.83740
2025-10-06 05:57:10.295 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.12673e-01, min=1.77301e-02, max=2.91432e-01
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6110.84
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:10.296 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:57:10.297 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.mlp.up_proj using 256 samples
2025-10-06 05:57:11.702 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4160.81787
2025-10-06 05:57:11.703 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.12673e-01, min=1.77301e-02, max=2.91432e-01
2025-10-06 05:57:11.703 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:57:11.703 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4160.82
2025-10-06 05:57:11.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:11.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:11.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:11.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:11.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:11.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:11.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:11.703 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:11.704 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:57:11.704 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.mlp.down_proj using 256 samples
2025-10-06 05:57:16.575 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 145.95467
2025-10-06 05:57:16.578 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.36222e-01, min=4.67617e-02, max=1.03183e+00
2025-10-06 05:57:16.578 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:57:16.578 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 145.95
2025-10-06 05:57:16.578 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:57:16.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:16.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:16.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:16.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:16.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:16.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:16.579 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:16.579 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:57:16.580 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:57:26.424 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:57:26.425 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.self_attn.q_proj using 256 samples
2025-10-06 05:57:27.787 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3661.52246
2025-10-06 05:57:27.788 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.00351e-01, min=1.17681e-02, max=1.96105e-01
2025-10-06 05:57:27.788 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:57:27.789 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3661.52
2025-10-06 05:57:27.789 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:57:27.789 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:27.789 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:27.789 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:27.789 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:27.789 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:27.789 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:27.789 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:27.789 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:57:27.790 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.self_attn.k_proj using 256 samples
2025-10-06 05:57:29.100 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1947.48926
2025-10-06 05:57:29.100 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.00351e-01, min=1.17681e-02, max=1.96105e-01
2025-10-06 05:57:29.100 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:57:29.101 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1947.49
2025-10-06 05:57:29.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:29.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:29.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:29.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:29.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:29.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:29.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:29.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:29.101 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:57:29.102 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.self_attn.v_proj using 256 samples
2025-10-06 05:57:30.410 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 290.90692
2025-10-06 05:57:30.411 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.00351e-01, min=1.17681e-02, max=1.96105e-01
2025-10-06 05:57:30.411 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:57:30.411 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 290.91
2025-10-06 05:57:30.411 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:30.411 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:30.411 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:30.412 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:30.412 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:30.412 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:30.412 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:30.412 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:30.412 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:57:30.413 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.self_attn.o_proj using 256 samples
2025-10-06 05:57:31.747 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 30.71136
2025-10-06 05:57:31.748 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.53053e-01, min=1.28695e-01, max=1.85019e+00
2025-10-06 05:57:31.748 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:57:31.748 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 30.71
2025-10-06 05:57:31.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:31.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:31.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:31.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:31.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:31.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:31.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:31.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:31.772 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:57:31.773 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.mlp.gate_proj using 256 samples
2025-10-06 05:57:33.178 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6125.11719
2025-10-06 05:57:33.179 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.13191e-01, min=2.00713e-02, max=3.30792e-01
2025-10-06 05:57:33.179 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:57:33.179 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6125.12
2025-10-06 05:57:33.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:33.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:33.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:33.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:33.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:33.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:33.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:33.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:33.180 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:57:33.181 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.mlp.up_proj using 256 samples
2025-10-06 05:57:34.584 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4086.23706
2025-10-06 05:57:34.585 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.13191e-01, min=2.00713e-02, max=3.30792e-01
2025-10-06 05:57:34.585 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:57:34.585 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4086.24
2025-10-06 05:57:34.585 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:34.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:34.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:34.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:34.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:34.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:34.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:34.586 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:34.586 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:57:34.587 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.mlp.down_proj using 256 samples
2025-10-06 05:57:39.461 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 146.28574
2025-10-06 05:57:39.464 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.44167e-01, min=4.79227e-02, max=1.23707e+00
2025-10-06 05:57:39.464 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 05:57:39.464 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 146.29
2025-10-06 05:57:39.465 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:57:39.465 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:39.465 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:39.465 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:39.465 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:39.465 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:39.465 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:39.465 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:39.465 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:57:39.466 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:57:49.313 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:57:49.313 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.self_attn.q_proj using 256 samples
2025-10-06 05:57:50.673 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3670.50903
2025-10-06 05:57:50.674 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.91664e-02, min=1.15795e-02, max=2.25012e-01
2025-10-06 05:57:50.674 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:57:50.674 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3670.51
2025-10-06 05:57:50.674 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:57:50.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:50.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:50.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:50.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:50.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:50.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:50.675 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:50.675 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:57:50.676 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.self_attn.k_proj using 256 samples
2025-10-06 05:57:51.991 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2108.73340
2025-10-06 05:57:51.992 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.91664e-02, min=1.15795e-02, max=2.25012e-01
2025-10-06 05:57:51.992 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:57:51.992 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2108.73
2025-10-06 05:57:51.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:51.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:51.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:51.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:51.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:51.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:51.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:51.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:51.993 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:57:51.994 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.self_attn.v_proj using 256 samples
2025-10-06 05:57:53.298 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 270.50681
2025-10-06 05:57:53.298 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.91664e-02, min=1.15795e-02, max=2.25012e-01
2025-10-06 05:57:53.298 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 05:57:53.299 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 270.51
2025-10-06 05:57:53.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:53.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:53.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:53.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:53.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:53.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:53.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:53.299 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:53.299 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:57:53.300 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.self_attn.o_proj using 256 samples
2025-10-06 05:57:54.626 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 22.12892
2025-10-06 05:57:54.627 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.00757e+00, min=1.21908e-01, max=2.73218e+00
2025-10-06 05:57:54.627 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:57:54.627 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 22.13
2025-10-06 05:57:54.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:54.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:54.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:54.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:54.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:54.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:54.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:54.628 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:54.628 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:57:54.629 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.mlp.gate_proj using 256 samples
2025-10-06 05:57:56.031 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6334.75781
2025-10-06 05:57:56.032 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.11208e-01, min=2.31801e-02, max=2.73107e-01
2025-10-06 05:57:56.032 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:57:56.033 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6334.76
2025-10-06 05:57:56.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:56.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:56.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:56.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:56.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:56.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:56.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:56.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:56.033 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:57:56.034 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.mlp.up_proj using 256 samples
2025-10-06 05:57:57.442 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4187.35449
2025-10-06 05:57:57.443 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.11208e-01, min=2.31801e-02, max=2.73107e-01
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4187.35
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:57:57.444 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:57:57.445 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.mlp.down_proj using 256 samples
2025-10-06 05:58:02.313 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 148.36421
2025-10-06 05:58:02.316 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.30753e-01, min=5.86485e-02, max=1.49754e+00
2025-10-06 05:58:02.316 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:58:02.316 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 148.36
2025-10-06 05:58:02.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:58:02.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:02.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:02.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:02.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:02.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:02.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:02.316 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:02.317 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:58:02.317 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:58:12.165 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:58:12.165 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.self_attn.q_proj using 256 samples
2025-10-06 05:58:13.532 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3787.25195
2025-10-06 05:58:13.532 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.72563e-02, min=1.33694e-02, max=1.94939e-01
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3787.25
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:13.533 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:58:13.534 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.self_attn.k_proj using 256 samples
2025-10-06 05:58:14.843 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1989.00867
2025-10-06 05:58:14.844 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.72563e-02, min=1.33694e-02, max=1.94939e-01
2025-10-06 05:58:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:58:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1989.01
2025-10-06 05:58:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:58:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:14.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:14.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:14.845 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:58:14.845 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.self_attn.v_proj using 256 samples
2025-10-06 05:58:16.151 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 301.86212
2025-10-06 05:58:16.152 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.72563e-02, min=1.33694e-02, max=1.94939e-01
2025-10-06 05:58:16.152 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:58:16.152 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 301.86
2025-10-06 05:58:16.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:58:16.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:16.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:16.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:16.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:16.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:16.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:16.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:16.153 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:58:16.154 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.self_attn.o_proj using 256 samples
2025-10-06 05:58:17.489 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 19.38206
2025-10-06 05:58:17.490 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.09043e+00, min=2.14245e-01, max=2.77882e+00
2025-10-06 05:58:17.490 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:58:17.490 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 19.38
2025-10-06 05:58:17.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:58:17.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:17.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:17.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:17.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:17.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:17.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:17.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:17.491 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:58:17.492 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.mlp.gate_proj using 256 samples
2025-10-06 05:58:18.898 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6852.90430
2025-10-06 05:58:18.899 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.07313e-01, min=2.37585e-02, max=3.15299e-01
2025-10-06 05:58:18.899 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:58:18.899 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6852.90
2025-10-06 05:58:18.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:58:18.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:18.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:18.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:18.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:18.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:18.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:18.900 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:18.900 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:58:18.901 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.mlp.up_proj using 256 samples
2025-10-06 05:58:20.310 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4471.75000
2025-10-06 05:58:20.311 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.07313e-01, min=2.37585e-02, max=3.15299e-01
2025-10-06 05:58:20.311 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:58:20.311 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4471.75
2025-10-06 05:58:20.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:58:20.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:20.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:20.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:20.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:20.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:20.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:20.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:20.312 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:58:20.313 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.mlp.down_proj using 256 samples
2025-10-06 05:58:25.190 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 166.30627
2025-10-06 05:58:25.192 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.94015e-01, min=4.22049e-02, max=1.43571e+00
2025-10-06 05:58:25.193 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 05:58:25.193 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 166.31
2025-10-06 05:58:25.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:58:25.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:25.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:25.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:25.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:25.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:25.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:25.196 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:25.196 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:58:25.197 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:58:35.017 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:58:35.018 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.self_attn.q_proj using 256 samples
2025-10-06 05:58:36.383 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3969.90332
2025-10-06 05:58:36.384 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.53095e-02, min=1.24049e-02, max=2.01901e-01
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3969.90
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:36.384 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:58:36.385 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.self_attn.k_proj using 256 samples
2025-10-06 05:58:37.707 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2088.81982
2025-10-06 05:58:37.708 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.53095e-02, min=1.24049e-02, max=2.01901e-01
2025-10-06 05:58:37.708 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:58:37.708 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2088.82
2025-10-06 05:58:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:58:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:37.709 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:58:37.710 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.self_attn.v_proj using 256 samples
2025-10-06 05:58:39.018 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 356.58752
2025-10-06 05:58:39.018 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.53095e-02, min=1.24049e-02, max=2.01901e-01
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 356.59
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:39.019 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:58:39.020 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.self_attn.o_proj using 256 samples
2025-10-06 05:58:40.355 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 31.07152
2025-10-06 05:58:40.356 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.00308e-01, min=1.38060e-01, max=2.19021e+00
2025-10-06 05:58:40.356 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:58:40.356 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 31.07
2025-10-06 05:58:40.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:58:40.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:40.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:40.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:40.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:40.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:40.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:40.360 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:40.360 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:58:40.361 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.mlp.gate_proj using 256 samples
2025-10-06 05:58:41.767 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 7552.22363
2025-10-06 05:58:41.768 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.02103e-01, min=2.50384e-02, max=3.08600e-01
2025-10-06 05:58:41.768 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:58:41.768 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7552.22
2025-10-06 05:58:41.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:58:41.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:41.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:41.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:41.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:41.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:41.769 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:41.769 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:41.769 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:58:41.770 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.mlp.up_proj using 256 samples
2025-10-06 05:58:43.171 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4958.99463
2025-10-06 05:58:43.172 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.02103e-01, min=2.50384e-02, max=3.08600e-01
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4958.99
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:43.173 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:58:43.174 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.mlp.down_proj using 256 samples
2025-10-06 05:58:48.041 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 196.89148
2025-10-06 05:58:48.044 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.43485e-01, min=6.79007e-02, max=1.19816e+00
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 196.89
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:48.044 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:58:48.046 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:58:58.178 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:58:58.178 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.self_attn.q_proj using 256 samples
2025-10-06 05:58:59.542 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4079.49316
2025-10-06 05:58:59.543 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.30960e-02, min=1.24927e-02, max=1.92742e-01
2025-10-06 05:58:59.543 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:58:59.544 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4079.49
2025-10-06 05:58:59.544 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:58:59.544 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:59.544 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:59.544 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:59.544 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:59.544 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:59.544 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:59.544 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:58:59.544 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:58:59.545 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.self_attn.k_proj using 256 samples
2025-10-06 05:59:00.861 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2221.93555
2025-10-06 05:59:00.861 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.30960e-02, min=1.24927e-02, max=1.92742e-01
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2221.94
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:00.862 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:59:00.863 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.self_attn.v_proj using 256 samples
2025-10-06 05:59:02.169 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 380.10550
2025-10-06 05:59:02.170 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.30960e-02, min=1.24927e-02, max=1.92742e-01
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 380.11
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:02.170 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:59:02.171 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.self_attn.o_proj using 256 samples
2025-10-06 05:59:03.503 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 29.08716
2025-10-06 05:59:03.504 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.69201e-01, min=9.72985e-02, max=1.93654e+00
2025-10-06 05:59:03.504 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:59:03.504 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 29.09
2025-10-06 05:59:03.505 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:03.505 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:03.505 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:03.505 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:03.505 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:03.505 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:03.505 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:03.505 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:03.505 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:59:03.506 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.mlp.gate_proj using 256 samples
2025-10-06 05:59:04.907 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 8461.20215
2025-10-06 05:59:04.908 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.69019e-02, min=2.57942e-02, max=2.81326e-01
2025-10-06 05:59:04.908 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:59:04.908 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8461.20
2025-10-06 05:59:04.908 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:04.908 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:04.908 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:04.908 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:04.908 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:04.908 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:04.909 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:04.909 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:04.909 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:59:04.910 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.mlp.up_proj using 256 samples
2025-10-06 05:59:06.310 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 5522.11621
2025-10-06 05:59:06.311 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.69019e-02, min=2.57942e-02, max=2.81326e-01
2025-10-06 05:59:06.311 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:59:06.311 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5522.12
2025-10-06 05:59:06.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:06.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:06.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:06.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:06.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:06.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:06.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:06.312 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:06.312 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:59:06.313 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.mlp.down_proj using 256 samples
2025-10-06 05:59:11.177 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 235.04245
2025-10-06 05:59:11.179 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.02726e-01, min=4.23277e-02, max=8.26996e-01
2025-10-06 05:59:11.179 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:59:11.180 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 235.04
2025-10-06 05:59:11.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:59:11.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:11.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:11.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:11.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:11.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:11.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:11.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:11.180 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:59:11.181 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:59:21.010 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:59:21.010 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.self_attn.q_proj using 256 samples
2025-10-06 05:59:22.371 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4162.85205
2025-10-06 05:59:22.372 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.95673e-02, min=1.26963e-02, max=2.00099e-01
2025-10-06 05:59:22.372 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:59:22.372 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4162.85
2025-10-06 05:59:22.372 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:59:22.372 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:22.372 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:22.372 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:22.372 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:22.373 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:22.373 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:22.373 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:22.373 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:59:22.373 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.self_attn.k_proj using 256 samples
2025-10-06 05:59:23.684 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2270.10449
2025-10-06 05:59:23.684 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.95673e-02, min=1.26963e-02, max=2.00099e-01
2025-10-06 05:59:23.684 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:59:23.685 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2270.10
2025-10-06 05:59:23.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:23.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:23.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:23.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:23.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:23.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:23.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:23.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:23.685 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:59:23.686 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.self_attn.v_proj using 256 samples
2025-10-06 05:59:24.993 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 467.77209
2025-10-06 05:59:24.994 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.95673e-02, min=1.26963e-02, max=2.00099e-01
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 467.77
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:24.994 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:59:24.995 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.self_attn.o_proj using 256 samples
2025-10-06 05:59:26.327 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 35.47734
2025-10-06 05:59:26.327 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.36404e-01, min=1.48712e-01, max=2.42788e+00
2025-10-06 05:59:26.327 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:59:26.328 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 35.48
2025-10-06 05:59:26.328 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:26.328 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:26.328 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:26.328 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:26.328 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:26.328 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:26.328 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:26.328 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:26.328 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:59:26.329 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.mlp.gate_proj using 256 samples
2025-10-06 05:59:27.735 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 9209.05273
2025-10-06 05:59:27.736 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.29818e-02, min=2.64828e-02, max=3.04003e-01
2025-10-06 05:59:27.736 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:59:27.736 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 9209.05
2025-10-06 05:59:27.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:27.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:27.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:27.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:27.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:27.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:27.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:27.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:27.737 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:59:27.738 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.mlp.up_proj using 256 samples
2025-10-06 05:59:29.144 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6063.78760
2025-10-06 05:59:29.145 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.29818e-02, min=2.64828e-02, max=3.04003e-01
2025-10-06 05:59:29.145 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:59:29.145 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6063.79
2025-10-06 05:59:29.146 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:29.146 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:29.146 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:29.146 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:29.146 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:29.146 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:29.146 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:29.146 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:29.146 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:59:29.147 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.mlp.down_proj using 256 samples
2025-10-06 05:59:34.017 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 257.22504
2025-10-06 05:59:34.019 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.75440e-01, min=5.65984e-02, max=8.50029e-01
2025-10-06 05:59:34.019 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:59:34.019 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 257.23
2025-10-06 05:59:34.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:59:34.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:34.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:34.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:34.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:34.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:34.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:34.020 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:34.020 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:59:34.021 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:59:43.791 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:59:43.792 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.self_attn.q_proj using 256 samples
2025-10-06 05:59:45.153 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4413.95898
2025-10-06 05:59:45.153 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.54124e-02, min=1.37576e-02, max=2.13829e-01
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4413.96
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:45.154 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:59:45.155 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.self_attn.k_proj using 256 samples
2025-10-06 05:59:46.498 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2330.48364
2025-10-06 05:59:46.499 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.54124e-02, min=1.37576e-02, max=2.13829e-01
2025-10-06 05:59:46.499 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:59:46.499 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2330.48
2025-10-06 05:59:46.505 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:46.506 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:46.506 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:46.506 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:46.506 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:46.506 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:46.506 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:46.506 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:46.506 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:59:46.507 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.self_attn.v_proj using 256 samples
2025-10-06 05:59:47.814 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 534.87415
2025-10-06 05:59:47.815 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.54124e-02, min=1.37576e-02, max=2.13829e-01
2025-10-06 05:59:47.815 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:59:47.815 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 534.87
2025-10-06 05:59:47.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:47.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:47.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:47.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:47.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:47.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:47.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:47.816 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:47.816 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:59:47.817 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.self_attn.o_proj using 256 samples
2025-10-06 05:59:49.147 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 26.42218
2025-10-06 05:59:49.148 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.97228e-01, min=1.33032e-01, max=2.08237e+00
2025-10-06 05:59:49.148 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:59:49.148 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 26.42
2025-10-06 05:59:49.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:49.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:49.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:49.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:49.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:49.148 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:49.149 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:49.149 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:49.149 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:59:49.149 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.mlp.gate_proj using 256 samples
2025-10-06 05:59:50.547 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 10297.83105
2025-10-06 05:59:50.548 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.78889e-02, min=2.83071e-02, max=2.64349e-01
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 10297.83
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:50.549 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:59:50.550 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.mlp.up_proj using 256 samples
2025-10-06 05:59:51.956 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6823.31201
2025-10-06 05:59:51.957 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.78889e-02, min=2.83071e-02, max=2.64349e-01
2025-10-06 05:59:51.957 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:59:51.957 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6823.31
2025-10-06 05:59:51.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:59:51.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:51.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:51.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:51.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:51.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:51.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:51.958 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:51.958 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:59:51.958 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.mlp.down_proj using 256 samples
2025-10-06 05:59:56.831 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 309.32520
2025-10-06 05:59:56.834 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.35986e-01, min=6.36086e-02, max=7.02036e-01
2025-10-06 05:59:56.834 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 05:59:56.834 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 309.33
2025-10-06 05:59:56.834 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:59:56.834 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:56.834 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:56.834 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:56.834 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:56.834 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:56.834 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:56.834 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:59:56.835 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:59:56.835 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:00:06.644 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 06:00:06.644 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.self_attn.q_proj using 256 samples
2025-10-06 06:00:08.072 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4437.11426
2025-10-06 06:00:08.073 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.39814e-02, min=1.37967e-02, max=2.14980e-01
2025-10-06 06:00:08.073 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.43s
2025-10-06 06:00:08.073 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4437.11
2025-10-06 06:00:08.074 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 06:00:08.074 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:08.074 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:08.074 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:08.074 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:08.074 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:08.074 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:08.074 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:08.074 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:00:08.075 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.self_attn.k_proj using 256 samples
2025-10-06 06:00:09.384 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2213.07251
2025-10-06 06:00:09.385 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.39814e-02, min=1.37967e-02, max=2.14980e-01
2025-10-06 06:00:09.385 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:00:09.385 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2213.07
2025-10-06 06:00:09.385 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:09.385 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:09.385 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:09.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:09.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:09.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:09.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:09.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:09.386 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:00:09.387 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.self_attn.v_proj using 256 samples
2025-10-06 06:00:10.692 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 642.61902
2025-10-06 06:00:10.693 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.39814e-02, min=1.37967e-02, max=2.14980e-01
2025-10-06 06:00:10.693 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:00:10.693 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 642.62
2025-10-06 06:00:10.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:10.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:10.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:10.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:10.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:10.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:10.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:10.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:10.694 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:00:10.695 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.self_attn.o_proj using 256 samples
2025-10-06 06:00:12.027 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 38.50478
2025-10-06 06:00:12.028 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.91423e-01, min=8.80254e-02, max=1.59352e+00
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 38.50
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:12.028 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:00:12.029 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.mlp.gate_proj using 256 samples
2025-10-06 06:00:13.434 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 11379.70508
2025-10-06 06:00:13.435 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.38667e-02, min=2.79907e-02, max=2.84089e-01
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11379.71
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:13.436 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:00:13.437 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.mlp.up_proj using 256 samples
2025-10-06 06:00:14.842 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 7517.82324
2025-10-06 06:00:14.843 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.38667e-02, min=2.79907e-02, max=2.84089e-01
2025-10-06 06:00:14.843 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 06:00:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7517.82
2025-10-06 06:00:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:14.844 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:00:14.845 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.mlp.down_proj using 256 samples
2025-10-06 06:00:19.720 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 362.64780
2025-10-06 06:00:19.723 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.03070e-01, min=5.85503e-02, max=6.14113e-01
2025-10-06 06:00:19.723 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 06:00:19.723 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 362.65
2025-10-06 06:00:19.723 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 06:00:19.723 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:19.723 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:19.723 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:19.723 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:19.723 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:19.723 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:19.723 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:19.724 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:00:19.724 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:00:29.558 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 06:00:29.558 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.self_attn.q_proj using 256 samples
2025-10-06 06:00:30.933 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4651.26270
2025-10-06 06:00:30.934 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.98975e-02, min=1.53162e-02, max=2.06162e-01
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4651.26
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:30.934 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:00:30.935 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.self_attn.k_proj using 256 samples
2025-10-06 06:00:32.242 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2319.07422
2025-10-06 06:00:32.243 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.98975e-02, min=1.53162e-02, max=2.06162e-01
2025-10-06 06:00:32.243 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:00:32.243 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2319.07
2025-10-06 06:00:32.243 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:32.243 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:32.243 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:32.244 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:32.244 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:32.244 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:32.244 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:32.244 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:32.244 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:00:32.245 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.self_attn.v_proj using 256 samples
2025-10-06 06:00:33.548 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 709.37921
2025-10-06 06:00:33.549 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.98975e-02, min=1.53162e-02, max=2.06162e-01
2025-10-06 06:00:33.549 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.30s
2025-10-06 06:00:33.549 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 709.38
2025-10-06 06:00:33.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:33.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:33.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:33.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:33.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:33.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:33.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:33.550 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:33.550 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:00:33.551 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.self_attn.o_proj using 256 samples
2025-10-06 06:00:34.884 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 40.91676
2025-10-06 06:00:34.884 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.22189e-01, min=9.12163e-02, max=1.56000e+00
2025-10-06 06:00:34.884 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 06:00:34.885 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 40.92
2025-10-06 06:00:34.885 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:34.885 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:34.885 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:34.885 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:34.885 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:34.885 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:34.885 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:34.885 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:34.885 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:00:34.886 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.mlp.gate_proj using 256 samples
2025-10-06 06:00:36.288 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 12817.28906
2025-10-06 06:00:36.289 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.93259e-02, min=2.80367e-02, max=2.67370e-01
2025-10-06 06:00:36.289 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 06:00:36.289 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 12817.29
2025-10-06 06:00:36.289 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:36.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:36.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:36.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:36.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:36.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:36.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:36.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:36.290 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:00:36.291 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.mlp.up_proj using 256 samples
2025-10-06 06:00:37.691 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 8445.29297
2025-10-06 06:00:37.692 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.93259e-02, min=2.80367e-02, max=2.67370e-01
2025-10-06 06:00:37.692 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 06:00:37.692 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8445.29
2025-10-06 06:00:37.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:37.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:37.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:37.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:37.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:37.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:37.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:37.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:37.693 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:00:37.693 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.mlp.down_proj using 256 samples
2025-10-06 06:00:42.569 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 445.12213
2025-10-06 06:00:42.572 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.67963e-01, min=2.21522e-02, max=6.68353e-01
2025-10-06 06:00:42.572 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 06:00:42.572 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 445.12
2025-10-06 06:00:42.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 06:00:42.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:42.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:42.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:42.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:42.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:42.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:42.573 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:42.573 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:00:42.574 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:00:52.223 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 06:00:52.224 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.self_attn.q_proj using 256 samples
2025-10-06 06:00:53.582 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4527.72314
2025-10-06 06:00:53.583 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.22558e-02, min=1.34608e-02, max=2.03957e-01
2025-10-06 06:00:53.583 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 06:00:53.583 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4527.72
2025-10-06 06:00:53.583 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 06:00:53.583 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:53.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:53.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:53.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:53.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:53.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:53.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:53.584 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:00:53.585 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.self_attn.k_proj using 256 samples
2025-10-06 06:00:54.892 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2401.71094
2025-10-06 06:00:54.893 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.22558e-02, min=1.34608e-02, max=2.03957e-01
2025-10-06 06:00:54.893 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:00:54.893 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2401.71
2025-10-06 06:00:54.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:54.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:54.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:54.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:54.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:54.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:54.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:54.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:54.894 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:00:54.895 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.self_attn.v_proj using 256 samples
2025-10-06 06:00:56.199 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 699.22333
2025-10-06 06:00:56.200 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.22558e-02, min=1.34608e-02, max=2.03957e-01
2025-10-06 06:00:56.200 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:00:56.200 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 699.22
2025-10-06 06:00:56.200 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:56.200 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:56.201 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:56.201 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:56.201 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:56.201 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:56.201 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:56.201 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:56.201 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:00:56.202 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.self_attn.o_proj using 256 samples
2025-10-06 06:00:57.535 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 52.84628
2025-10-06 06:00:57.535 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.55838e-01, min=9.43196e-02, max=1.60243e+00
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 52.85
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:57.536 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:00:57.537 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.mlp.gate_proj using 256 samples
2025-10-06 06:00:58.934 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 13999.26758
2025-10-06 06:00:58.935 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.60793e-02, min=2.50360e-02, max=2.58707e-01
2025-10-06 06:00:58.935 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 06:00:58.935 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 13999.27
2025-10-06 06:00:58.935 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:00:58.935 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:58.936 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:58.936 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:58.936 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:58.936 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:58.936 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:58.936 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:00:58.936 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:00:58.937 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.mlp.up_proj using 256 samples
2025-10-06 06:01:00.346 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 9205.83789
2025-10-06 06:01:00.347 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.60793e-02, min=2.50360e-02, max=2.58707e-01
2025-10-06 06:01:00.347 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 06:01:00.347 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 9205.84
2025-10-06 06:01:00.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:00.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:00.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:00.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:00.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:00.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:00.348 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:00.348 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:00.348 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:01:00.349 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.mlp.down_proj using 256 samples
2025-10-06 06:01:05.222 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 519.69946
2025-10-06 06:01:05.224 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.44963e-01, min=4.03191e-02, max=7.92004e-01
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 519.70
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:05.225 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:01:05.226 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:01:15.157 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 06:01:15.157 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.self_attn.q_proj using 256 samples
2025-10-06 06:01:16.526 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4927.99414
2025-10-06 06:01:16.527 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.61912e-02, min=1.56389e-02, max=2.90239e-01
2025-10-06 06:01:16.527 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 06:01:16.528 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4927.99
2025-10-06 06:01:16.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 06:01:16.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:16.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:16.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:16.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:16.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:16.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:16.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:16.530 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:01:16.531 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.self_attn.k_proj using 256 samples
2025-10-06 06:01:17.842 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2641.51562
2025-10-06 06:01:17.843 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.61912e-02, min=1.56389e-02, max=2.90239e-01
2025-10-06 06:01:17.843 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:01:17.843 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2641.52
2025-10-06 06:01:17.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:17.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:17.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:17.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:17.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:17.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:17.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:17.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:17.844 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:01:17.844 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.self_attn.v_proj using 256 samples
2025-10-06 06:01:19.150 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 926.74634
2025-10-06 06:01:19.150 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.61912e-02, min=1.56389e-02, max=2.90239e-01
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 926.75
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:19.151 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:01:19.152 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.self_attn.o_proj using 256 samples
2025-10-06 06:01:20.487 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 75.09738
2025-10-06 06:01:20.488 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.05288e-01, min=3.19785e-02, max=1.66835e+00
2025-10-06 06:01:20.488 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 06:01:20.488 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 75.10
2025-10-06 06:01:20.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:20.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:20.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:20.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:20.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:20.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:20.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:20.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:20.489 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:01:20.490 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.mlp.gate_proj using 256 samples
2025-10-06 06:01:21.893 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 15671.99219
2025-10-06 06:01:21.894 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.22807e-02, min=2.55843e-02, max=2.34043e-01
2025-10-06 06:01:21.894 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 06:01:21.894 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 15671.99
2025-10-06 06:01:21.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:21.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:21.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:21.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:21.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:21.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:21.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:21.894 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:21.895 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:01:21.895 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.mlp.up_proj using 256 samples
2025-10-06 06:01:23.299 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 10269.71875
2025-10-06 06:01:23.300 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.22807e-02, min=2.55843e-02, max=2.34043e-01
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 10269.72
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:23.301 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:01:23.302 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.mlp.down_proj using 256 samples
2025-10-06 06:01:28.173 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 642.31726
2025-10-06 06:01:28.175 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.16877e-01, min=2.03622e-02, max=6.50642e-01
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 642.32
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:28.176 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:01:28.177 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:01:38.013 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 06:01:38.013 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.self_attn.q_proj using 256 samples
2025-10-06 06:01:39.375 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4765.29980
2025-10-06 06:01:39.376 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.68405e-02, min=1.59643e-02, max=1.84494e-01
2025-10-06 06:01:39.376 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 06:01:39.376 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4765.30
2025-10-06 06:01:39.377 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 06:01:39.377 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:39.377 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:39.377 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:39.377 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:39.377 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:39.377 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:39.377 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:39.377 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:01:39.378 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.self_attn.k_proj using 256 samples
2025-10-06 06:01:40.684 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2312.60107
2025-10-06 06:01:40.684 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.68405e-02, min=1.59643e-02, max=1.84494e-01
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2312.60
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:40.685 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:01:40.686 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.self_attn.v_proj using 256 samples
2025-10-06 06:01:41.990 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 945.02344
2025-10-06 06:01:41.991 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.68405e-02, min=1.59643e-02, max=1.84494e-01
2025-10-06 06:01:41.991 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:01:41.991 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 945.02
2025-10-06 06:01:41.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:41.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:41.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:41.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:41.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:41.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:41.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:41.993 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:41.993 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:01:41.994 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.self_attn.o_proj using 256 samples
2025-10-06 06:01:43.328 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 121.15134
2025-10-06 06:01:43.329 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.64167e-01, min=7.90193e-02, max=1.16664e+00
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 121.15
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:43.330 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:01:43.331 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.mlp.gate_proj using 256 samples
2025-10-06 06:01:44.731 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 16088.40430
2025-10-06 06:01:44.732 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.04973e-02, min=2.63600e-02, max=2.08681e-01
2025-10-06 06:01:44.732 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 06:01:44.732 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 16088.40
2025-10-06 06:01:44.733 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:44.733 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:44.733 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:44.733 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:44.733 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:44.733 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:44.733 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:44.733 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:44.733 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:01:44.734 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.mlp.up_proj using 256 samples
2025-10-06 06:01:46.138 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 10893.96191
2025-10-06 06:01:46.139 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.04973e-02, min=2.63600e-02, max=2.08681e-01
2025-10-06 06:01:46.139 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 06:01:46.140 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 10893.96
2025-10-06 06:01:46.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:01:46.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:46.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:46.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:46.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:46.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:46.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:46.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:46.140 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:01:46.141 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.mlp.down_proj using 256 samples
2025-10-06 06:01:51.011 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 715.51953
2025-10-06 06:01:51.013 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.08382e-01, min=2.36441e-02, max=7.70545e-01
2025-10-06 06:01:51.014 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 06:01:51.014 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 715.52
2025-10-06 06:01:51.015 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 06:01:51.016 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:51.016 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:51.016 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:51.016 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:51.016 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:51.016 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:51.016 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:01:51.016 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:01:51.017 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:02:00.863 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 06:02:00.863 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.self_attn.q_proj using 256 samples
2025-10-06 06:02:02.224 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4889.22754
2025-10-06 06:02:02.225 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.37520e-02, min=1.62753e-02, max=2.76166e-01
2025-10-06 06:02:02.225 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 06:02:02.226 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4889.23
2025-10-06 06:02:02.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 06:02:02.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:02.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:02.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:02.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:02.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:02.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:02.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:02.226 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:02:02.227 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.self_attn.k_proj using 256 samples
2025-10-06 06:02:03.536 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2609.22876
2025-10-06 06:02:03.536 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.37520e-02, min=1.62753e-02, max=2.76166e-01
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2609.23
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:03.537 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:02:03.538 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.self_attn.v_proj using 256 samples
2025-10-06 06:02:04.844 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1055.97388
2025-10-06 06:02:04.844 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.37520e-02, min=1.62753e-02, max=2.76166e-01
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1055.97
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:04.845 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:02:04.846 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.self_attn.o_proj using 256 samples
2025-10-06 06:02:06.182 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 98.72511
2025-10-06 06:02:06.182 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.52113e-01, min=5.75874e-02, max=1.27686e+00
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 98.73
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:06.183 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:02:06.184 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.mlp.gate_proj using 256 samples
2025-10-06 06:02:07.588 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 16239.69922
2025-10-06 06:02:07.589 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.98591e-02, min=2.06304e-02, max=1.89485e-01
2025-10-06 06:02:07.589 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 06:02:07.589 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 16239.70
2025-10-06 06:02:07.589 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:07.589 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:07.590 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:07.590 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:07.590 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:07.590 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:07.590 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:07.590 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:07.590 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:02:07.591 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.mlp.up_proj using 256 samples
2025-10-06 06:02:08.994 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 11390.41211
2025-10-06 06:02:08.995 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.98591e-02, min=2.06304e-02, max=1.89485e-01
2025-10-06 06:02:08.995 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 06:02:08.995 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11390.41
2025-10-06 06:02:08.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:08.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:08.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:08.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:08.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:08.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:08.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:08.996 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:08.996 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:02:08.997 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.mlp.down_proj using 256 samples
2025-10-06 06:02:13.879 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 845.83948
2025-10-06 06:02:13.881 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.92950e-01, min=2.30847e-02, max=7.09637e-01
2025-10-06 06:02:13.881 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 06:02:13.881 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 845.84
2025-10-06 06:02:13.882 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 06:02:13.882 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:13.882 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:13.882 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:13.882 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:13.882 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:13.882 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:13.882 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:13.882 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:02:13.883 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:02:23.695 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 06:02:23.695 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.self_attn.q_proj using 256 samples
2025-10-06 06:02:25.061 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4213.73438
2025-10-06 06:02:25.062 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.00976e-02, min=1.64164e-02, max=1.90122e-01
2025-10-06 06:02:25.062 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 06:02:25.063 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4213.73
2025-10-06 06:02:25.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 06:02:25.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:25.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:25.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:25.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:25.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:25.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:25.063 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:25.063 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:02:25.064 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.self_attn.k_proj using 256 samples
2025-10-06 06:02:26.384 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1910.23315
2025-10-06 06:02:26.385 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.00976e-02, min=1.64164e-02, max=1.90122e-01
2025-10-06 06:02:26.385 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 06:02:26.385 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1910.23
2025-10-06 06:02:26.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:26.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:26.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:26.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:26.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:26.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:26.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:26.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:26.386 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:02:26.387 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.self_attn.v_proj using 256 samples
2025-10-06 06:02:27.691 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1300.93909
2025-10-06 06:02:27.692 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.00976e-02, min=1.64164e-02, max=1.90122e-01
2025-10-06 06:02:27.692 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:02:27.692 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1300.94
2025-10-06 06:02:27.692 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:27.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:27.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:27.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:27.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:27.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:27.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:27.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:27.693 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:02:27.694 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.self_attn.o_proj using 256 samples
2025-10-06 06:02:29.024 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 219.32265
2025-10-06 06:02:29.025 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.88889e-01, min=5.33023e-02, max=1.11940e+00
2025-10-06 06:02:29.025 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 06:02:29.025 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 219.32
2025-10-06 06:02:29.025 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:29.026 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:29.026 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:29.026 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:29.026 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:29.026 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:29.026 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:29.026 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:29.026 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:02:29.027 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.mlp.gate_proj using 256 samples
2025-10-06 06:02:30.434 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 16619.49414
2025-10-06 06:02:30.435 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.11226e-02, min=2.34147e-02, max=1.88609e-01
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 16619.49
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:30.436 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:02:30.437 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.mlp.up_proj using 256 samples
2025-10-06 06:02:31.845 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 11212.14258
2025-10-06 06:02:31.845 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.11226e-02, min=2.34147e-02, max=1.88609e-01
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11212.14
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:31.846 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:02:31.847 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.mlp.down_proj using 256 samples
2025-10-06 06:02:36.718 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1042.96265
2025-10-06 06:02:36.721 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.79052e-01, min=2.12720e-02, max=7.03365e-01
2025-10-06 06:02:36.721 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 06:02:36.721 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1042.96
2025-10-06 06:02:36.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 06:02:36.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:36.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:36.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:36.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:36.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:36.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:36.772 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:36.772 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:02:36.773 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:02:46.498 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 06:02:46.499 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.self_attn.q_proj using 256 samples
2025-10-06 06:02:47.863 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3300.84521
2025-10-06 06:02:47.864 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.57419e-02, min=2.35860e-02, max=2.66513e-01
2025-10-06 06:02:47.864 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 06:02:47.864 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3300.85
2025-10-06 06:02:47.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 06:02:47.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:47.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:47.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:47.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:47.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:47.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:47.865 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:47.865 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:02:47.866 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.self_attn.k_proj using 256 samples
2025-10-06 06:02:49.178 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1520.57227
2025-10-06 06:02:49.179 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.57419e-02, min=2.35860e-02, max=2.66513e-01
2025-10-06 06:02:49.179 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:02:49.179 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1520.57
2025-10-06 06:02:49.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:49.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:49.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:49.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:49.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:49.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:49.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:49.180 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:49.180 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:02:49.181 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.self_attn.v_proj using 256 samples
2025-10-06 06:02:50.488 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 728.89069
2025-10-06 06:02:50.489 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.57419e-02, min=2.35860e-02, max=2.66513e-01
2025-10-06 06:02:50.489 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 06:02:50.489 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 728.89
2025-10-06 06:02:50.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:50.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:50.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:50.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:50.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:50.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:50.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:50.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:50.490 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 06:02:50.491 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.self_attn.o_proj using 256 samples
2025-10-06 06:02:51.823 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 186.68318
2025-10-06 06:02:51.824 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.21007e-01, min=4.84733e-02, max=9.71385e-01
2025-10-06 06:02:51.824 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 06:02:51.824 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 186.68
2025-10-06 06:02:51.824 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:51.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:51.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:51.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:51.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:51.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:51.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:51.825 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:51.825 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 06:02:51.826 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.mlp.gate_proj using 256 samples
2025-10-06 06:02:53.228 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 13231.18750
2025-10-06 06:02:53.229 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.96224e-02, min=1.85518e-02, max=3.17304e-01
2025-10-06 06:02:53.229 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 06:02:53.229 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 13231.19
2025-10-06 06:02:53.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:53.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:53.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:53.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:53.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:53.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:53.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:53.230 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:53.230 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:02:53.231 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.mlp.up_proj using 256 samples
2025-10-06 06:02:54.633 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 8983.78711
2025-10-06 06:02:54.634 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.96224e-02, min=1.85518e-02, max=3.17304e-01
2025-10-06 06:02:54.634 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 06:02:54.635 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8983.79
2025-10-06 06:02:54.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 06:02:54.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:54.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:54.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:54.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:54.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:54.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:54.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:54.635 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:02:54.636 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.mlp.down_proj using 256 samples
2025-10-06 06:02:59.516 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2308.54883
2025-10-06 06:02:59.519 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.16914e-01, min=6.59035e-03, max=3.74602e-01
2025-10-06 06:02:59.519 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 06:02:59.519 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2308.55
2025-10-06 06:02:59.520 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 06:02:59.520 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:59.520 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:59.520 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:59.520 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:59.520 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:59.520 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:59.520 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 06:02:59.520 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 06:02:59.521 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:03:02.671 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 06:03:02.671 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:03:04.244 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_END
2025-10-06 06:03:04.248 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:03:04.250 | DEBUG    | llmcompressor.core.lifecycle:finalize:134 - Finalizing compression lifecycle
2025-10-06 06:03:04.251 | DEBUG    | llmcompressor.core.lifecycle:finalize:138 - Finalized modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=True started_=True ended_=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 06:03:04.251 | INFO     | llmcompressor.core.lifecycle:finalize:144 - Compression lifecycle finalized for 1 modifiers
2025-10-06 06:03:04.286 | WARNING  | llmcompressor.entrypoints.utils:post_process:142 - Optimized model is not saved. To save, please provide`output_dir` as input arg.Ex. `oneshot(..., output_dir=...)`
2025-10-06 06:03:42.327 | INFO     | llmcompressor.transformers.compression.compressed_tensors_utils:get_model_compressor:193 - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.
2025-10-06 06:04:28.689 | DEBUG    | llmcompressor.transformers.utils.helpers:recipe_from_huggingface_model_id:146 - Unable to find recipe recipe.yaml for model ID: nvidia/Llama-3.1-Nemotron-Nano-8B-v1: 404 Client Error. (Request ID: Root=1-68e3be5c-7bbc619b4e65b9bf5f8934cd;997f7073-dd2e-427d-a734-953e5559a98f)

Entry Not Found for url: https://huggingface.co/nvidia/Llama-3.1-Nemotron-Nano-8B-v1/resolve/main/recipe.yaml..Skipping recipe resolution.
2025-10-06 06:04:28.690 | DEBUG    | llmcompressor.transformers.utils.helpers:infer_recipe_from_model_path:112 - Failed to infer the recipe from the model_path
