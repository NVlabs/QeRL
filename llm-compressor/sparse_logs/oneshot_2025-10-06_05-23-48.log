2025-10-06 05:23:58.993 | DEBUG    | llmcompressor.transformers.finetune.data.base:__call__:100 - Raw dataset: ['input', 'output', 'instruction', 'data_source', 'text']
2025-10-06 05:23:58.993 | DEBUG    | llmcompressor.transformers.finetune.data.base:__call__:116 - Dataset after column renaming: ['input', 'output', 'instruction', 'data_source', 'text']
2025-10-06 05:23:58.994 | DEBUG    | llmcompressor.transformers.finetune.data.base:filter_tokenizer_args:248 - Found processor args `{'return_length', 'padding', 'return_tensors', 'return_token_type_ids', 'return_offsets_mapping', 'text_pair', 'padding_side', 'verbose', 'return_overflowing_tokens', 'return_attention_mask', 'is_split_into_words', 'pad_to_multiple_of', 'truncation', 'stride', 'text', 'text_target', 'add_special_tokens', 'max_length', 'return_special_tokens_mask', 'text_pair_target'}`. Removing all other columns
2025-10-06 05:23:58.996 | DEBUG    | llmcompressor.transformers.finetune.data.base:__call__:123 - Tokenizer args after filtering: ['text']
2025-10-06 05:23:59.410 | DEBUG    | llmcompressor.transformers.finetune.data.base:__call__:137 - Model kwargs after tokenizing: ['input_ids', 'attention_mask']
2025-10-06 05:23:59.410 | DEBUG    | llmcompressor.transformers.finetune.data.base:__call__:167 - Model kwargs after postprocessing: ['input_ids', 'attention_mask']
2025-10-06 05:23:59.416 | DEBUG    | llmcompressor.core.lifecycle:reset:59 - Resetting compression lifecycle
2025-10-06 05:23:59.416 | INFO     | llmcompressor.core.lifecycle:reset:71 - Compression lifecycle reset
2025-10-06 05:23:59.416 | DEBUG    | llmcompressor.core.state:update:182 - Updating state with provided parameters: {'model': LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(128256, 4096)
    (layers): ModuleList(
      (0-31): 32 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)
          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)
          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)
          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)
          (act_fn): SiLUActivation()
        )
        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)
      )
    )
    (norm): LlamaRMSNorm((4096,), eps=1e-05)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)
), 'teacher_model': None, 'optimizer': None, 'attach_optim_callbacks': True, 'train_data': None, 'val_data': None, 'test_data': None, 'calib_data': <torch.utils.data.dataloader.DataLoader object at 0x15518c458a70>, 'copy_data': True, 'start': -1, 'steps_per_epoch': None, 'batches_per_step': None, 'loggers': None, 'model_log_cadence': None, 'kwargs': {}}
2025-10-06 05:23:59.421 | INFO     | llmcompressor.metrics.logger:_create_default_logger:357 - Logging all LLM Compressor modifier-level logs to sparse_logs/06-10-2025_05.23.59.log
2025-10-06 05:23:59.423 | DEBUG    | llmcompressor.core.lifecycle:initialize:92 - Initializing compression lifecycle
2025-10-06 05:23:59.423 | INFO     | llmcompressor.recipe.recipe:from_modifiers:68 - Creating recipe from modifiers
2025-10-06 05:23:59.540 | DEBUG    | llmcompressor.core.lifecycle:initialize:105 - Initialized modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=False ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:23:59.540 | INFO     | llmcompressor.core.lifecycle:initialize:110 - Compression lifecycle initialized for 1 modifiers
2025-10-06 05:23:59.540 | INFO     | llmcompressor.pipelines.independent.pipeline:IndependentPipeline:43 - Inferred `SequentialPipeline` for `GPTQModifier`
2025-10-06 05:24:01.209 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:24:01.210 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(kwargs, labels, logits, loss):
    if labels is not None:
        loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.vocab_size, **kwargs)
    return (loss,)
2025-10-06 05:24:01.210 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:24:01.213 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:24:01.213 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_0(input_ids, inputs_embeds):
    if (input_ids is None) ^ (inputs_embeds is not None):
        raise ValueError('You must specify exactly one of input_ids or inputs_embeds')
    return ()
2025-10-06 05:24:01.213 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:24:01.213 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:24:01.213 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_1(input_ids, inputs_embeds):
    if inputs_embeds is None:
        inputs_embeds: torch.Tensor = self.embed_tokens(input_ids)
    return (inputs_embeds,)
2025-10-06 05:24:01.213 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:24:01.213 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:24:01.213 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_2(past_key_values, use_cache):
    if use_cache and past_key_values is None:
        past_key_values = DynamicCache(config=self.config)
    return (past_key_values,)
2025-10-06 05:24:01.214 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:24:01.214 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:24:01.214 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_3(cache_position, inputs_embeds, past_key_values, *, past_seen_tokens=None):
    if cache_position is None:
        past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0
        cache_position: torch.Tensor = torch.arange(past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device)
    return (cache_position, past_seen_tokens)
2025-10-06 05:24:01.214 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:24:01.214 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:24:01.214 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_4(cache_position, position_ids):
    if position_ids is None:
        position_ids = cache_position.unsqueeze(0)
    return (position_ids,)
2025-10-06 05:24:01.214 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:24:01.214 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:267 - ---- Autowrapper ----
2025-10-06 05:24:01.215 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:268 - @torch.fx.wrap
def wrapped_5(attention_mask, cache_position, inputs_embeds, past_key_values, position_ids):
    return create_causal_mask(config=self.config, input_embeds=inputs_embeds, attention_mask=attention_mask, cache_position=cache_position, past_key_values=past_key_values, position_ids=position_ids)
    return ()
2025-10-06 05:24:01.215 | DEBUG    | llmcompressor.pipelines.sequential.ast_utils.auto_wrapper:_wrap_stmt:269 - ---------------------
2025-10-06 05:24:01.401 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_START
2025-10-06 05:24:01.412 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155084188da0>
2025-10-06 05:24:01.412 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155084108320>
2025-10-06 05:24:01.412 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf8680>
2025-10-06 05:24:01.412 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf8bc0>
2025-10-06 05:24:01.412 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf94f0>
2025-10-06 05:24:01.412 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf9e50>
2025-10-06 05:24:01.412 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfa990>
2025-10-06 05:24:01.412 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf9430>
2025-10-06 05:24:01.412 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfaa20>
2025-10-06 05:24:01.412 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfa9f0>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfad20>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf9c40>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfa810>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf85f0>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf8b00>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfa7b0>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfa600>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf9b50>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf96d0>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfa000>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf9880>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfa090>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf9970>
2025-10-06 05:24:01.413 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfaae0>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfab40>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfa6c0>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf8530>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cf9fd0>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfac30>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfae70>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfa4e0>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfb290>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfb440>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfb1a0>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfb590>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfb320>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfb4a0>
2025-10-06 05:24:01.414 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cb1d30>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfb7d0>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfb7a0>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfbfe0>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187ca72f0>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550841d9e20>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550841dbe30>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550841dbec0>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550841dbfb0>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1580e0>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1581a0>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158290>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155084189d90>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1583e0>
2025-10-06 05:24:01.415 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1584d0>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158470>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158620>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550841898b0>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1587a0>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1588c0>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158830>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1589b0>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158a70>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158b60>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158c50>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158d40>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158e60>
2025-10-06 05:24:01.416 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x155187cfba70>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158f80>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac158f20>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159100>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1591f0>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1592e0>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159400>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159490>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159580>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159670>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159760>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159850>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159730>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159a00>
2025-10-06 05:24:01.417 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159a90>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159b50>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159a30>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159d00>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159d90>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159e50>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159ee0>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159eb0>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159f70>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a000>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a150>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a210>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a2d0>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a3c0>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a480>
2025-10-06 05:24:01.418 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a420>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a600>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a6f0>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a7e0>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a8d0>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15a990>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15aa80>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15ab10>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15abd0>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15ac60>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15ad20>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15ae10>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15acc0>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15af90>
2025-10-06 05:24:01.419 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b080>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b140>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b230>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b2f0>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b290>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b470>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b500>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b4a0>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b650>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b710>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b6e0>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b860>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b920>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15b9e0>
2025-10-06 05:24:01.420 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15ba70>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15bb00>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15bbc0>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15bc80>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15bc20>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15bda0>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15be90>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15be30>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15bf80>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1740e0>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1741a0>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174230>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174290>
2025-10-06 05:24:01.421 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174350>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174410>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1744d0>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174590>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174680>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174770>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174860>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174950>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac15bf20>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174a70>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174a10>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174b90>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174c50>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174d10>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174dd0>
2025-10-06 05:24:01.422 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174ec0>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174e30>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175040>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1750d0>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1751c0>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1752b0>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1753a0>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175460>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15508418a270>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175550>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175520>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1756d0>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175610>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175850>
2025-10-06 05:24:01.423 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175940>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175a00>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175af0>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175a60>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175c40>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175d00>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175cd0>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175df0>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175ee0>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175fd0>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac175e80>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176030>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1761e0>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1762d0>
2025-10-06 05:24:01.424 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1763c0>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176360>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1764e0>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1765a0>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176660>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1764b0>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1767b0>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1768a0>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176960>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176a20>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176b10>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176c00>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176d20>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176cc0>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176d50>
2025-10-06 05:24:01.425 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176ea0>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176e40>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac176f90>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177050>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177140>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac174440>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177290>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177380>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177440>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177500>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177590>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177620>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1776e0>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1775f0>
2025-10-06 05:24:01.426 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177890>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177950>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x15508418a1b0>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177a70>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177b60>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177c50>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177d10>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177e00>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177ec0>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac177fb0>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac159520>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac190170>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac190260>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac190320>
2025-10-06 05:24:01.427 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac190410>
2025-10-06 05:24:01.428 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1904d0>
2025-10-06 05:24:01.428 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac1905c0>
2025-10-06 05:24:01.428 | DEBUG    | llmcompressor.modifiers.utils.hooks:register_hook:98 - config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False added <torch.utils.hooks.RemovableHandle object at 0x1550ac190530>
2025-10-06 05:24:01.428 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:24:11.879 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:24:11.880 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.self_attn.q_proj using 256 samples
2025-10-06 05:24:15.620 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 212.56331
2025-10-06 05:24:15.620 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.02530e+00, min=3.42642e-02, max=1.23983e+00
2025-10-06 05:24:15.620 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 3.74s
2025-10-06 05:24:15.620 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 212.56
2025-10-06 05:24:15.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.77% | total memory: 85 GB
2025-10-06 05:24:15.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:15.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:15.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:15.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:15.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:15.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:15.621 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:15.621 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:24:15.622 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.self_attn.k_proj using 256 samples
2025-10-06 05:24:17.568 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 96.12247
2025-10-06 05:24:17.568 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.02530e+00, min=3.42642e-02, max=1.23983e+00
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.95s
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 96.12
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.77% | total memory: 85 GB
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:17.569 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:24:17.570 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.self_attn.v_proj using 256 samples
2025-10-06 05:24:18.883 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2.34044
2025-10-06 05:24:18.883 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.02530e+00, min=3.42642e-02, max=1.23983e+00
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.34
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.78% | total memory: 85 GB
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:18.884 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:24:18.885 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.self_attn.o_proj using 256 samples
2025-10-06 05:24:20.219 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 0.31442
2025-10-06 05:24:20.219 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.36611e+01, min=8.12984e-01, max=2.10406e+01
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.31
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.78% | total memory: 85 GB
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:20.220 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:24:20.221 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.mlp.gate_proj using 256 samples
2025-10-06 05:24:21.625 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 62.84479
2025-10-06 05:24:21.626 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01158e+00, min=2.02318e-01, max=1.96368e+00
2025-10-06 05:24:21.626 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:24:21.626 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 62.84
2025-10-06 05:24:21.626 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.78% | total memory: 85 GB
2025-10-06 05:24:21.626 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:21.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:21.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:21.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:21.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:21.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:21.627 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:21.627 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:24:21.628 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.mlp.up_proj using 256 samples
2025-10-06 05:24:23.032 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 53.63581
2025-10-06 05:24:23.033 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01158e+00, min=2.02318e-01, max=1.96368e+00
2025-10-06 05:24:23.033 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:24:23.033 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 53.64
2025-10-06 05:24:23.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.78% | total memory: 85 GB
2025-10-06 05:24:23.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:23.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:23.033 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:23.034 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:23.034 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:23.034 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:23.034 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:23.034 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:24:23.035 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.0.mlp.down_proj using 256 samples
2025-10-06 05:24:27.899 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1.07717
2025-10-06 05:24:27.902 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.17279e+01, min=1.64232e-01, max=1.56044e+01
2025-10-06 05:24:27.902 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.87s
2025-10-06 05:24:27.902 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.08
2025-10-06 05:24:27.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 8.70% | total memory: 85 GB
2025-10-06 05:24:27.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:27.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:27.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:27.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:27.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:27.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:27.902 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:27.903 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:24:27.903 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:24:40.061 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:24:40.061 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.self_attn.q_proj using 256 samples
2025-10-06 05:24:41.429 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 235.32809
2025-10-06 05:24:41.430 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.33389e-01, min=2.97879e-02, max=8.00799e-01
2025-10-06 05:24:41.430 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:24:41.430 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 235.33
2025-10-06 05:24:41.440 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:24:41.440 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:41.440 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:41.440 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:41.440 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:41.440 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:41.440 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:41.440 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:41.440 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:24:41.441 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.self_attn.k_proj using 256 samples
2025-10-06 05:24:42.754 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 127.13521
2025-10-06 05:24:42.755 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.33389e-01, min=2.97879e-02, max=8.00799e-01
2025-10-06 05:24:42.755 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:24:42.755 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 127.14
2025-10-06 05:24:42.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:24:42.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:42.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:42.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:42.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:42.756 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:42.756 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:42.756 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:42.756 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:24:42.757 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.self_attn.v_proj using 256 samples
2025-10-06 05:24:44.066 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 7.82325
2025-10-06 05:24:44.067 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.33389e-01, min=2.97879e-02, max=8.00799e-01
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7.82
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:44.068 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:24:44.069 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.self_attn.o_proj using 256 samples
2025-10-06 05:24:45.402 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 0.22874
2025-10-06 05:24:45.403 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01086e+01, min=1.25334e+00, max=2.14611e+01
2025-10-06 05:24:45.403 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:24:45.403 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 0.23
2025-10-06 05:24:45.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:24:45.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:45.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:45.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:45.403 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:45.404 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:45.404 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:45.404 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:45.404 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:24:45.405 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.mlp.gate_proj using 256 samples
2025-10-06 05:24:46.814 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 164.05014
2025-10-06 05:24:46.815 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.15070e-01, min=1.60657e-01, max=1.23361e+00
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 164.05
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:46.815 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:24:46.816 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.mlp.up_proj using 256 samples
2025-10-06 05:24:48.226 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 141.77301
2025-10-06 05:24:48.227 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.15070e-01, min=1.60657e-01, max=1.23361e+00
2025-10-06 05:24:48.227 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:24:48.227 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 141.77
2025-10-06 05:24:48.228 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.55% | total memory: 85 GB
2025-10-06 05:24:48.228 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:48.228 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:48.228 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:48.228 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:48.228 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:48.228 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:48.228 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:48.228 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:24:48.229 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.1.mlp.down_proj using 256 samples
2025-10-06 05:24:53.128 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1209.95764
2025-10-06 05:24:53.131 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.92527e-01, min=5.27399e-03, max=9.01315e-01
2025-10-06 05:24:53.131 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.90s
2025-10-06 05:24:53.131 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1209.96
2025-10-06 05:24:53.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.47% | total memory: 85 GB
2025-10-06 05:24:53.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:53.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:53.131 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:53.132 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:53.132 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:53.132 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:53.132 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:24:53.132 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:24:53.133 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:25:03.943 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:25:03.944 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.self_attn.q_proj using 256 samples
2025-10-06 05:25:05.330 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 631.31238
2025-10-06 05:25:05.331 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.11366e-01, min=2.52037e-02, max=6.29924e-01
2025-10-06 05:25:05.331 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.39s
2025-10-06 05:25:05.331 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 631.31
2025-10-06 05:25:05.332 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:25:05.332 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:05.332 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:05.332 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:05.332 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:05.332 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:05.332 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:05.332 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:05.332 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:25:05.333 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.self_attn.k_proj using 256 samples
2025-10-06 05:25:06.649 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 377.00540
2025-10-06 05:25:06.650 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.11366e-01, min=2.52037e-02, max=6.29924e-01
2025-10-06 05:25:06.650 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:25:06.650 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 377.01
2025-10-06 05:25:06.676 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:25:06.676 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:06.676 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:06.676 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:25:06.678 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.self_attn.v_proj using 256 samples
2025-10-06 05:25:07.988 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 23.14161
2025-10-06 05:25:07.989 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.11366e-01, min=2.52037e-02, max=6.29924e-01
2025-10-06 05:25:07.989 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:25:07.989 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 23.14
2025-10-06 05:25:07.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:25:07.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:07.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:07.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:07.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:07.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:07.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:07.990 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:07.990 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:25:07.991 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.self_attn.o_proj using 256 samples
2025-10-06 05:25:09.321 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1.60313
2025-10-06 05:25:09.321 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.40926e+00, min=2.09774e-01, max=3.22660e+00
2025-10-06 05:25:09.321 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:25:09.322 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.60
2025-10-06 05:25:09.322 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:25:09.322 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:09.322 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:09.322 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:09.322 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:09.322 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:09.322 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:09.322 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:09.322 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:25:09.323 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.mlp.gate_proj using 256 samples
2025-10-06 05:25:10.728 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 380.38742
2025-10-06 05:25:10.729 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.32192e-01, min=1.90228e-02, max=1.10586e+00
2025-10-06 05:25:10.729 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:25:10.729 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 380.39
2025-10-06 05:25:10.729 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:25:10.729 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:10.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:10.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:10.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:10.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:10.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:10.730 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:10.730 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:25:10.731 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.mlp.up_proj using 256 samples
2025-10-06 05:25:12.137 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 306.19080
2025-10-06 05:25:12.138 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.32192e-01, min=1.90228e-02, max=1.10586e+00
2025-10-06 05:25:12.138 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:25:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 306.19
2025-10-06 05:25:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.51% | total memory: 85 GB
2025-10-06 05:25:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:25:12.140 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.2.mlp.down_proj using 256 samples
2025-10-06 05:25:17.020 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1.95674
2025-10-06 05:25:17.023 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.68134e+00, min=4.49711e-01, max=8.55741e+00
2025-10-06 05:25:17.023 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 05:25:17.023 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.96
2025-10-06 05:25:17.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.47% | total memory: 85 GB
2025-10-06 05:25:17.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:17.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:17.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:17.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:17.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:17.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:17.024 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:17.024 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:25:17.025 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:25:27.143 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:25:27.143 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.self_attn.q_proj using 256 samples
2025-10-06 05:25:28.514 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 749.62811
2025-10-06 05:25:28.515 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.32103e-01, min=2.63282e-02, max=5.72098e-01
2025-10-06 05:25:28.515 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:25:28.515 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 749.63
2025-10-06 05:25:28.515 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:25:28.515 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:28.515 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:28.515 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:28.515 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:28.516 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:28.516 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:28.516 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:28.516 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:25:28.517 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.self_attn.k_proj using 256 samples
2025-10-06 05:25:29.835 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 406.83881
2025-10-06 05:25:29.836 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.32103e-01, min=2.63282e-02, max=5.72098e-01
2025-10-06 05:25:29.836 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:25:29.836 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 406.84
2025-10-06 05:25:29.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:25:29.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:29.837 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:29.837 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:29.837 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:29.837 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:29.837 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:29.837 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:29.837 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:25:29.838 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.self_attn.v_proj using 256 samples
2025-10-06 05:25:31.152 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 40.84747
2025-10-06 05:25:31.153 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.32103e-01, min=2.63282e-02, max=5.72098e-01
2025-10-06 05:25:31.153 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:25:31.153 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 40.85
2025-10-06 05:25:31.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:25:31.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:31.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:31.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:31.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:31.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:31.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:31.153 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:31.154 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:25:31.154 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.self_attn.o_proj using 256 samples
2025-10-06 05:25:32.491 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1.02927
2025-10-06 05:25:32.492 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.63959e+00, min=2.92720e-01, max=7.70019e+00
2025-10-06 05:25:32.492 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:25:32.492 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1.03
2025-10-06 05:25:32.493 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:25:32.493 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:32.493 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:32.493 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:32.493 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:32.493 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:32.493 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:32.493 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:32.493 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:25:32.494 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.mlp.gate_proj using 256 samples
2025-10-06 05:25:33.903 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 665.97638
2025-10-06 05:25:33.904 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.30260e-01, min=2.04595e-02, max=8.96127e-01
2025-10-06 05:25:33.904 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:25:33.904 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 665.98
2025-10-06 05:25:33.922 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:25:33.923 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:33.923 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:33.923 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:33.923 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:33.923 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:33.923 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:33.923 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:33.923 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:25:33.924 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.mlp.up_proj using 256 samples
2025-10-06 05:25:35.332 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 484.86981
2025-10-06 05:25:35.333 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.30260e-01, min=2.04595e-02, max=8.96127e-01
2025-10-06 05:25:35.333 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:25:35.333 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 484.87
2025-10-06 05:25:35.334 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:25:35.334 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:35.334 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:35.334 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:35.334 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:35.334 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:35.334 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:35.334 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:35.334 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:25:35.335 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.3.mlp.down_proj using 256 samples
2025-10-06 05:25:40.236 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4.37853
2025-10-06 05:25:40.239 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.64084e+00, min=2.26453e-01, max=5.84299e+00
2025-10-06 05:25:40.239 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.90s
2025-10-06 05:25:40.239 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.38
2025-10-06 05:25:40.239 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.59% | total memory: 85 GB
2025-10-06 05:25:40.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:40.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:40.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:40.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:40.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:40.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:40.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:40.240 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:25:40.241 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:25:50.333 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:25:50.333 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.self_attn.q_proj using 256 samples
2025-10-06 05:25:51.692 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 801.73688
2025-10-06 05:25:51.693 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.28746e-01, min=2.08622e-02, max=5.53162e-01
2025-10-06 05:25:51.693 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:25:51.693 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 801.74
2025-10-06 05:25:51.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:25:51.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:51.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:51.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:51.693 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:51.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:51.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:51.694 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:51.694 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:25:51.695 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.self_attn.k_proj using 256 samples
2025-10-06 05:25:53.002 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 442.06787
2025-10-06 05:25:53.003 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.28746e-01, min=2.08622e-02, max=5.53162e-01
2025-10-06 05:25:53.003 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:25:53.004 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 442.07
2025-10-06 05:25:53.004 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:25:53.004 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:53.004 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:53.004 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:53.004 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:53.004 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:53.004 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:53.004 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:53.004 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:25:53.005 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.self_attn.v_proj using 256 samples
2025-10-06 05:25:54.313 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 47.79294
2025-10-06 05:25:54.314 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.28746e-01, min=2.08622e-02, max=5.53162e-01
2025-10-06 05:25:54.314 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:25:54.314 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 47.79
2025-10-06 05:25:54.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:25:54.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:54.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:54.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:54.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:54.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:54.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:54.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:54.315 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:25:54.316 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.self_attn.o_proj using 256 samples
2025-10-06 05:25:55.647 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2.44491
2025-10-06 05:25:55.648 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.41806e+00, min=4.50767e-01, max=4.77956e+00
2025-10-06 05:25:55.648 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:25:55.648 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2.44
2025-10-06 05:25:55.648 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:25:55.648 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:55.648 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:55.649 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:55.649 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:55.649 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:55.649 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:55.649 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:55.649 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:25:55.650 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.mlp.gate_proj using 256 samples
2025-10-06 05:25:57.055 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1110.70996
2025-10-06 05:25:57.056 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.62967e-01, min=1.74684e-02, max=7.61795e-01
2025-10-06 05:25:57.056 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:25:57.056 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1110.71
2025-10-06 05:25:57.056 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:25:57.056 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:57.056 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:57.056 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:57.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:57.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:57.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:57.057 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:57.057 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:25:57.058 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.mlp.up_proj using 256 samples
2025-10-06 05:25:58.465 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 719.34406
2025-10-06 05:25:58.466 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.62967e-01, min=1.74684e-02, max=7.61795e-01
2025-10-06 05:25:58.466 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:25:58.466 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 719.34
2025-10-06 05:25:58.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:25:58.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:58.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:58.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:58.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:58.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:58.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:58.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:25:58.467 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:25:58.468 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.4.mlp.down_proj using 256 samples
2025-10-06 05:26:03.345 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 8.36425
2025-10-06 05:26:03.348 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.53218e+00, min=3.21196e-01, max=4.18838e+00
2025-10-06 05:26:03.348 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 05:26:03.348 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8.36
2025-10-06 05:26:03.349 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.59% | total memory: 85 GB
2025-10-06 05:26:03.349 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:03.349 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:03.349 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:03.349 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:03.349 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:03.349 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:03.349 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:03.349 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:26:03.350 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:26:13.468 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:26:13.469 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.self_attn.q_proj using 256 samples
2025-10-06 05:26:14.837 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1348.84351
2025-10-06 05:26:14.838 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.78539e-01, min=1.24865e-02, max=3.03039e-01
2025-10-06 05:26:14.838 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:26:14.838 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1348.84
2025-10-06 05:26:14.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:26:14.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:14.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:14.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:14.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:14.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:14.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:14.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:14.841 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:26:14.842 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.self_attn.k_proj using 256 samples
2025-10-06 05:26:16.153 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 763.46478
2025-10-06 05:26:16.154 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.78539e-01, min=1.24865e-02, max=3.03039e-01
2025-10-06 05:26:16.154 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:26:16.154 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 763.46
2025-10-06 05:26:16.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:26:16.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:16.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:16.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:16.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:16.154 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:16.155 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:16.155 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:16.155 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:26:16.155 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.self_attn.v_proj using 256 samples
2025-10-06 05:26:17.464 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 59.56218
2025-10-06 05:26:17.465 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.78539e-01, min=1.24865e-02, max=3.03039e-01
2025-10-06 05:26:17.465 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:26:17.465 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 59.56
2025-10-06 05:26:17.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:26:17.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:17.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:17.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:17.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:17.468 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:17.468 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:17.468 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:17.468 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:26:17.468 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.self_attn.o_proj using 256 samples
2025-10-06 05:26:18.803 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4.36738
2025-10-06 05:26:18.804 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.67320e+00, min=1.54525e-01, max=3.58152e+00
2025-10-06 05:26:18.804 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:26:18.804 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4.37
2025-10-06 05:26:18.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:26:18.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:18.804 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:18.805 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:18.805 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:18.805 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:18.805 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:18.805 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:18.805 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:26:18.806 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.mlp.gate_proj using 256 samples
2025-10-06 05:26:20.211 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1602.47717
2025-10-06 05:26:20.212 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.17923e-01, min=1.54252e-02, max=6.77412e-01
2025-10-06 05:26:20.212 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:26:20.212 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1602.48
2025-10-06 05:26:20.212 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:26:20.213 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:20.213 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:20.213 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:20.213 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:20.213 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:20.213 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:20.213 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:20.213 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:26:20.214 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.mlp.up_proj using 256 samples
2025-10-06 05:26:21.613 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1045.97656
2025-10-06 05:26:21.614 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.17923e-01, min=1.54252e-02, max=6.77412e-01
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.40s
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1045.98
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:21.615 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:26:21.616 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.5.mlp.down_proj using 256 samples
2025-10-06 05:26:26.466 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 16.03848
2025-10-06 05:26:26.469 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.84461e+00, min=1.27507e-01, max=3.32333e+00
2025-10-06 05:26:26.469 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.85s
2025-10-06 05:26:26.469 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 16.04
2025-10-06 05:26:26.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.59% | total memory: 85 GB
2025-10-06 05:26:26.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:26.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:26.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:26.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:26.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:26.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:26.470 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:26.470 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:26:26.470 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:26:36.565 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:26:36.565 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.self_attn.q_proj using 256 samples
2025-10-06 05:26:37.989 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1577.55103
2025-10-06 05:26:37.990 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.59799e-01, min=1.07329e-02, max=2.88469e-01
2025-10-06 05:26:37.990 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:26:37.990 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1577.55
2025-10-06 05:26:37.991 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:26:37.991 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:37.991 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:37.991 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:37.991 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:37.991 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:37.991 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:37.991 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:37.991 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:26:37.992 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.self_attn.k_proj using 256 samples
2025-10-06 05:26:39.318 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 859.56787
2025-10-06 05:26:39.319 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.59799e-01, min=1.07329e-02, max=2.88469e-01
2025-10-06 05:26:39.319 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:26:39.319 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 859.57
2025-10-06 05:26:39.320 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:26:39.320 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:39.320 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:39.320 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:39.320 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:39.320 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:39.320 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:39.320 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:39.320 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:26:39.321 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.self_attn.v_proj using 256 samples
2025-10-06 05:26:40.633 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 77.53760
2025-10-06 05:26:40.634 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.59799e-01, min=1.07329e-02, max=2.88469e-01
2025-10-06 05:26:40.634 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:26:40.634 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 77.54
2025-10-06 05:26:40.634 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:26:40.634 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:40.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:40.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:40.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:40.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:40.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:40.635 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:40.635 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:26:40.636 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.self_attn.o_proj using 256 samples
2025-10-06 05:26:41.976 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 7.40899
2025-10-06 05:26:41.977 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.27047e+00, min=2.06717e-01, max=2.82454e+00
2025-10-06 05:26:41.977 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:26:41.978 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7.41
2025-10-06 05:26:41.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:26:41.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:41.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:41.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:41.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:41.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:41.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:41.978 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:41.978 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:26:41.979 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.mlp.gate_proj using 256 samples
2025-10-06 05:26:43.390 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2124.81641
2025-10-06 05:26:43.391 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.89499e-01, min=1.41509e-02, max=6.15684e-01
2025-10-06 05:26:43.391 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:26:43.391 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2124.82
2025-10-06 05:26:43.391 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:26:43.392 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:43.392 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:43.392 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:43.392 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:43.392 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:43.392 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:43.392 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:43.392 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:26:43.393 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.mlp.up_proj using 256 samples
2025-10-06 05:26:44.801 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1373.21606
2025-10-06 05:26:44.802 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.89499e-01, min=1.41509e-02, max=6.15684e-01
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1373.22
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:44.803 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:26:44.804 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.6.mlp.down_proj using 256 samples
2025-10-06 05:26:49.723 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 24.57542
2025-10-06 05:26:49.725 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.45833e+00, min=2.95039e-01, max=2.45912e+00
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.92s
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 24.58
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 6.59% | total memory: 85 GB
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:26:49.726 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:26:49.727 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:26:59.840 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:26:59.840 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.self_attn.q_proj using 256 samples
2025-10-06 05:27:01.214 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1715.29382
2025-10-06 05:27:01.215 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.43159e-01, min=1.20051e-02, max=2.71152e-01
2025-10-06 05:27:01.215 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:27:01.215 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1715.29
2025-10-06 05:27:01.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:27:01.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:01.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:01.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:01.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:01.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:01.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:01.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:01.216 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:27:01.217 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.self_attn.k_proj using 256 samples
2025-10-06 05:27:02.532 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1011.01215
2025-10-06 05:27:02.533 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.43159e-01, min=1.20051e-02, max=2.71152e-01
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1011.01
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:02.534 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:27:02.535 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.self_attn.v_proj using 256 samples
2025-10-06 05:27:03.849 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 89.76199
2025-10-06 05:27:03.850 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.43159e-01, min=1.20051e-02, max=2.71152e-01
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 89.76
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:03.850 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:27:03.851 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.self_attn.o_proj using 256 samples
2025-10-06 05:27:05.191 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 11.09648
2025-10-06 05:27:05.192 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.03533e+00, min=1.55303e-01, max=1.83601e+00
2025-10-06 05:27:05.192 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:27:05.192 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11.10
2025-10-06 05:27:05.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:05.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:05.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:05.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:05.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:05.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:05.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:05.199 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:05.199 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:27:05.200 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.mlp.gate_proj using 256 samples
2025-10-06 05:27:06.612 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2419.59912
2025-10-06 05:27:06.613 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.73592e-01, min=1.58166e-02, max=4.06328e-01
2025-10-06 05:27:06.613 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:27:06.613 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2419.60
2025-10-06 05:27:06.676 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:06.677 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:27:06.678 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.mlp.up_proj using 256 samples
2025-10-06 05:27:08.085 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1651.25610
2025-10-06 05:27:08.086 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.73592e-01, min=1.58166e-02, max=4.06328e-01
2025-10-06 05:27:08.086 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:27:08.086 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1651.26
2025-10-06 05:27:08.086 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:08.086 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:08.086 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:08.086 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:08.086 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:08.086 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:08.086 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:08.086 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:08.087 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:27:08.087 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.7.mlp.down_proj using 256 samples
2025-10-06 05:27:12.977 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 34.20795
2025-10-06 05:27:12.980 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.25094e+00, min=1.54725e-01, max=2.26963e+00
2025-10-06 05:27:12.980 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.89s
2025-10-06 05:27:12.980 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 34.21
2025-10-06 05:27:12.980 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:27:12.980 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:12.980 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:12.980 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:12.980 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:12.981 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:12.981 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:12.981 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:12.981 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:27:12.982 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:27:23.033 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:27:23.033 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.self_attn.q_proj using 256 samples
2025-10-06 05:27:24.405 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2228.27246
2025-10-06 05:27:24.406 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.25598e-01, min=1.64868e-02, max=2.35120e-01
2025-10-06 05:27:24.406 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:27:24.406 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2228.27
2025-10-06 05:27:24.406 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:27:24.406 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:24.406 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:24.406 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:24.406 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:24.406 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:24.406 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:24.406 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:24.407 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:27:24.407 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.self_attn.k_proj using 256 samples
2025-10-06 05:27:25.754 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1267.73413
2025-10-06 05:27:25.755 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.25598e-01, min=1.64868e-02, max=2.35120e-01
2025-10-06 05:27:25.755 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:27:25.755 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1267.73
2025-10-06 05:27:25.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:25.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:25.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:25.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:25.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:25.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:25.755 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:25.756 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:25.756 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:27:25.756 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.self_attn.v_proj using 256 samples
2025-10-06 05:27:27.071 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 127.10550
2025-10-06 05:27:27.072 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.25598e-01, min=1.64868e-02, max=2.35120e-01
2025-10-06 05:27:27.072 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:27:27.072 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 127.11
2025-10-06 05:27:27.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:27.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:27.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:27.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:27.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:27.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:27.072 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:27.073 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:27.073 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:27:27.073 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.self_attn.o_proj using 256 samples
2025-10-06 05:27:28.416 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 18.69359
2025-10-06 05:27:28.417 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.49162e-01, min=6.77571e-02, max=1.63305e+00
2025-10-06 05:27:28.417 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:27:28.417 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 18.69
2025-10-06 05:27:28.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:28.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:28.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:28.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:28.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:28.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:28.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:28.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:28.418 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:27:28.419 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.mlp.gate_proj using 256 samples
2025-10-06 05:27:29.832 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2900.36182
2025-10-06 05:27:29.833 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.59679e-01, min=1.50676e-02, max=5.71139e-01
2025-10-06 05:27:29.833 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:27:29.833 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2900.36
2025-10-06 05:27:29.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:29.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:29.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:29.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:29.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:29.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:29.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:29.835 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:29.836 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:27:29.836 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.mlp.up_proj using 256 samples
2025-10-06 05:27:31.246 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 1965.39124
2025-10-06 05:27:31.247 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.59679e-01, min=1.50676e-02, max=5.71139e-01
2025-10-06 05:27:31.247 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:27:31.247 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1965.39
2025-10-06 05:27:31.247 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:31.247 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:31.247 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:31.247 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:31.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:31.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:31.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:31.248 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:31.248 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:27:31.249 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.8.mlp.down_proj using 256 samples
2025-10-06 05:27:36.140 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 43.05602
2025-10-06 05:27:36.143 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.11359e+00, min=2.49784e-01, max=1.88888e+00
2025-10-06 05:27:36.143 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.89s
2025-10-06 05:27:36.143 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 43.06
2025-10-06 05:27:36.143 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:27:36.143 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:36.143 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:36.143 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:36.144 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:36.144 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:36.144 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:36.144 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:36.144 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:27:36.145 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:27:46.413 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:27:46.413 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.self_attn.q_proj using 256 samples
2025-10-06 05:27:47.786 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2489.87109
2025-10-06 05:27:47.787 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.18605e-01, min=1.49371e-02, max=2.08169e-01
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2489.87
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:47.787 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:27:47.788 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.self_attn.k_proj using 256 samples
2025-10-06 05:27:49.101 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1405.75244
2025-10-06 05:27:49.102 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.18605e-01, min=1.49371e-02, max=2.08169e-01
2025-10-06 05:27:49.102 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:27:49.102 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1405.75
2025-10-06 05:27:49.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:49.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:49.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:49.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:49.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:49.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:49.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:49.103 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:49.103 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:27:49.104 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.self_attn.v_proj using 256 samples
2025-10-06 05:27:50.417 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 180.58632
2025-10-06 05:27:50.417 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.18605e-01, min=1.49371e-02, max=2.08169e-01
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 180.59
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:50.418 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:27:50.419 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.self_attn.o_proj using 256 samples
2025-10-06 05:27:51.758 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 23.77592
2025-10-06 05:27:51.759 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.16701e-01, min=5.57596e-02, max=2.04996e+00
2025-10-06 05:27:51.759 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:27:51.759 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 23.78
2025-10-06 05:27:51.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:51.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:51.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:51.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:51.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:51.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:51.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:51.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:51.760 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:27:51.761 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.mlp.gate_proj using 256 samples
2025-10-06 05:27:53.165 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3344.88037
2025-10-06 05:27:53.166 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.50672e-01, min=1.45670e-02, max=3.86149e-01
2025-10-06 05:27:53.166 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:27:53.166 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3344.88
2025-10-06 05:27:53.166 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:53.166 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:53.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:53.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:53.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:53.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:53.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:53.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:53.167 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:27:53.168 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.mlp.up_proj using 256 samples
2025-10-06 05:27:54.573 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2259.38794
2025-10-06 05:27:54.574 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.50672e-01, min=1.45670e-02, max=3.86149e-01
2025-10-06 05:27:54.574 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:27:54.574 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2259.39
2025-10-06 05:27:54.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:27:54.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:54.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:54.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:54.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:54.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:54.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:54.575 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:54.575 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:27:54.576 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.9.mlp.down_proj using 256 samples
2025-10-06 05:27:59.488 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 52.63602
2025-10-06 05:27:59.491 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01719e+00, min=1.30932e-01, max=1.75584e+00
2025-10-06 05:27:59.491 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.92s
2025-10-06 05:27:59.491 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 52.64
2025-10-06 05:27:59.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:27:59.492 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:59.492 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:59.492 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:59.492 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:59.492 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:59.492 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:59.492 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:27:59.492 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:27:59.493 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:28:09.726 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:28:09.726 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.self_attn.q_proj using 256 samples
2025-10-06 05:28:11.103 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3017.81592
2025-10-06 05:28:11.104 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.09882e-01, min=1.36580e-02, max=2.14040e-01
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3017.82
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:11.105 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:28:11.106 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.self_attn.k_proj using 256 samples
2025-10-06 05:28:12.423 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1682.76685
2025-10-06 05:28:12.424 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.09882e-01, min=1.36580e-02, max=2.14040e-01
2025-10-06 05:28:12.424 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:28:12.424 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1682.77
2025-10-06 05:28:12.424 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:12.424 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:12.424 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:12.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:12.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:12.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:12.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:12.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:12.425 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:28:12.426 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.self_attn.v_proj using 256 samples
2025-10-06 05:28:13.742 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 167.54898
2025-10-06 05:28:13.743 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.09882e-01, min=1.36580e-02, max=2.14040e-01
2025-10-06 05:28:13.743 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:28:13.743 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 167.55
2025-10-06 05:28:13.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:13.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:13.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:13.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:13.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:13.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:13.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:13.744 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:13.744 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:28:13.745 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.self_attn.o_proj using 256 samples
2025-10-06 05:28:15.086 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 24.08457
2025-10-06 05:28:15.087 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.47982e-01, min=5.87583e-02, max=1.59300e+00
2025-10-06 05:28:15.087 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:28:15.087 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 24.08
2025-10-06 05:28:15.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:15.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:15.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:15.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:15.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:15.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:15.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:15.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:15.088 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:28:15.089 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.mlp.gate_proj using 256 samples
2025-10-06 05:28:16.505 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3594.41064
2025-10-06 05:28:16.506 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.42737e-01, min=1.57342e-02, max=3.88487e-01
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3594.41
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:16.507 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:28:16.508 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.mlp.up_proj using 256 samples
2025-10-06 05:28:17.925 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2596.98022
2025-10-06 05:28:17.926 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.42737e-01, min=1.57342e-02, max=3.88487e-01
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2596.98
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:17.927 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:28:17.928 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.10.mlp.down_proj using 256 samples
2025-10-06 05:28:22.837 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 64.92835
2025-10-06 05:28:22.840 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.29991e-01, min=4.68558e-02, max=1.53458e+00
2025-10-06 05:28:22.840 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.91s
2025-10-06 05:28:22.840 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 64.93
2025-10-06 05:28:22.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:28:22.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:22.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:22.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:22.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:22.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:22.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:22.841 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:22.841 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:28:22.842 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:28:32.987 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:28:32.987 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.self_attn.q_proj using 256 samples
2025-10-06 05:28:34.359 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3013.89453
2025-10-06 05:28:34.360 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.03919e-01, min=1.32692e-02, max=1.96538e-01
2025-10-06 05:28:34.360 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:28:34.360 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3013.89
2025-10-06 05:28:34.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:28:34.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:34.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:34.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:34.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:34.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:34.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:34.361 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:34.361 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:28:34.362 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.self_attn.k_proj using 256 samples
2025-10-06 05:28:35.694 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1784.33472
2025-10-06 05:28:35.695 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.03919e-01, min=1.32692e-02, max=1.96538e-01
2025-10-06 05:28:35.695 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.33s
2025-10-06 05:28:35.695 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1784.33
2025-10-06 05:28:35.696 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:35.696 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:35.696 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:35.696 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:35.696 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:35.696 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:35.696 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:35.696 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:35.696 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:28:35.697 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.self_attn.v_proj using 256 samples
2025-10-06 05:28:37.011 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 182.82407
2025-10-06 05:28:37.012 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.03919e-01, min=1.32692e-02, max=1.96538e-01
2025-10-06 05:28:37.012 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:28:37.012 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 182.82
2025-10-06 05:28:37.012 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:37.012 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:37.012 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:37.012 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:37.012 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:37.013 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:37.013 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:37.013 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:37.013 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:28:37.013 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.self_attn.o_proj using 256 samples
2025-10-06 05:28:38.354 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 27.23858
2025-10-06 05:28:38.355 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.09469e-01, min=1.28733e-01, max=1.37586e+00
2025-10-06 05:28:38.355 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:28:38.355 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 27.24
2025-10-06 05:28:38.355 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:38.355 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:38.355 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:38.355 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:38.355 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:38.355 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:38.355 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:38.355 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:38.356 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:28:38.356 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.mlp.gate_proj using 256 samples
2025-10-06 05:28:39.769 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3952.54858
2025-10-06 05:28:39.770 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.33978e-01, min=1.62655e-02, max=3.39012e-01
2025-10-06 05:28:39.770 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:28:39.770 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3952.55
2025-10-06 05:28:39.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:39.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:39.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:39.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:39.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:39.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:39.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:39.771 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:39.771 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:28:39.772 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.mlp.up_proj using 256 samples
2025-10-06 05:28:41.184 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 2950.88379
2025-10-06 05:28:41.185 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.33978e-01, min=1.62655e-02, max=3.39012e-01
2025-10-06 05:28:41.185 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:28:41.185 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2950.88
2025-10-06 05:28:41.222 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:41.222 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:41.222 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:41.223 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:41.223 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:41.223 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:41.223 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:41.223 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:41.223 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:28:41.224 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.11.mlp.down_proj using 256 samples
2025-10-06 05:28:46.126 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 78.00941
2025-10-06 05:28:46.129 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.48836e-01, min=5.56567e-02, max=1.41883e+00
2025-10-06 05:28:46.129 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.91s
2025-10-06 05:28:46.129 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 78.01
2025-10-06 05:28:46.129 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:28:46.129 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:46.129 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:46.129 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:46.130 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:46.130 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:46.130 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:46.130 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:46.130 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:28:46.131 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:28:56.208 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:28:56.209 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.self_attn.q_proj using 256 samples
2025-10-06 05:28:57.582 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2786.46802
2025-10-06 05:28:57.583 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.08728e-01, min=9.36880e-03, max=2.13471e-01
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2786.47
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:57.584 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:28:57.585 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.self_attn.k_proj using 256 samples
2025-10-06 05:28:58.900 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1539.21448
2025-10-06 05:28:58.901 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.08728e-01, min=9.36880e-03, max=2.13471e-01
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1539.21
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:28:58.901 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:28:58.902 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.self_attn.v_proj using 256 samples
2025-10-06 05:29:00.212 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 224.65097
2025-10-06 05:29:00.213 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.08728e-01, min=9.36880e-03, max=2.13471e-01
2025-10-06 05:29:00.213 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:29:00.213 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 224.65
2025-10-06 05:29:00.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:00.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:00.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:00.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:00.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:00.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:00.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:00.214 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:00.214 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:29:00.215 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.self_attn.o_proj using 256 samples
2025-10-06 05:29:01.559 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 33.99503
2025-10-06 05:29:01.560 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.71023e-01, min=6.89006e-02, max=1.25041e+00
2025-10-06 05:29:01.560 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:29:01.560 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 34.00
2025-10-06 05:29:01.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:01.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:01.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:01.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:01.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:01.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:01.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:01.560 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:01.561 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:29:01.561 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.mlp.gate_proj using 256 samples
2025-10-06 05:29:02.973 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4040.60059
2025-10-06 05:29:02.974 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.30534e-01, min=1.46247e-02, max=2.99568e-01
2025-10-06 05:29:02.974 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:29:02.974 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4040.60
2025-10-06 05:29:02.974 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:02.975 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:02.975 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:02.975 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:02.975 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:02.975 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:02.975 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:02.975 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:02.975 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:29:02.976 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.mlp.up_proj using 256 samples
2025-10-06 05:29:04.393 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3176.32812
2025-10-06 05:29:04.394 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.30534e-01, min=1.46247e-02, max=2.99568e-01
2025-10-06 05:29:04.394 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:29:04.394 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3176.33
2025-10-06 05:29:04.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:04.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:04.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:04.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:04.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:04.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:04.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:04.394 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:04.395 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:29:04.395 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.12.mlp.down_proj using 256 samples
2025-10-06 05:29:09.312 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 83.65489
2025-10-06 05:29:09.315 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.27417e-01, min=9.83059e-02, max=1.40137e+00
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.92s
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 83.65
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:09.315 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:29:09.316 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:29:19.457 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:29:19.458 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.self_attn.q_proj using 256 samples
2025-10-06 05:29:20.841 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3712.68604
2025-10-06 05:29:20.842 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.52348e-02, min=1.30031e-02, max=1.84883e-01
2025-10-06 05:29:20.842 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:29:20.842 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3712.69
2025-10-06 05:29:20.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:29:20.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:20.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:20.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:20.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:20.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:20.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:20.843 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:20.843 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:29:20.844 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.self_attn.k_proj using 256 samples
2025-10-06 05:29:22.166 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2161.10059
2025-10-06 05:29:22.166 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.52348e-02, min=1.30031e-02, max=1.84883e-01
2025-10-06 05:29:22.166 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:29:22.167 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2161.10
2025-10-06 05:29:22.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:22.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:22.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:22.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:22.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:22.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:22.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:22.167 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:22.167 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:29:22.168 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.self_attn.v_proj using 256 samples
2025-10-06 05:29:23.488 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 259.08496
2025-10-06 05:29:23.488 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.52348e-02, min=1.30031e-02, max=1.84883e-01
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 259.08
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:23.489 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:29:23.490 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.self_attn.o_proj using 256 samples
2025-10-06 05:29:24.838 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 42.31512
2025-10-06 05:29:24.839 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.73185e-01, min=1.17201e-01, max=1.03455e+00
2025-10-06 05:29:24.839 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:29:24.840 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 42.32
2025-10-06 05:29:24.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:24.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:24.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:24.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:24.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:24.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:24.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:24.840 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:24.840 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:29:24.841 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.mlp.gate_proj using 256 samples
2025-10-06 05:29:26.252 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4439.34082
2025-10-06 05:29:26.253 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.24824e-01, min=1.52097e-02, max=3.34092e-01
2025-10-06 05:29:26.253 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:29:26.253 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4439.34
2025-10-06 05:29:26.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:26.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:26.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:26.253 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:26.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:26.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:26.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:26.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:26.254 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:29:26.255 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.mlp.up_proj using 256 samples
2025-10-06 05:29:27.669 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3513.51587
2025-10-06 05:29:27.670 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.24824e-01, min=1.52097e-02, max=3.34092e-01
2025-10-06 05:29:27.670 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:29:27.671 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3513.52
2025-10-06 05:29:27.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:27.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:27.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:27.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:27.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:27.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:27.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:27.671 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:27.671 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:29:27.672 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.13.mlp.down_proj using 256 samples
2025-10-06 05:29:32.795 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 94.84524
2025-10-06 05:29:32.797 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.87099e-01, min=1.34338e-01, max=1.34041e+00
2025-10-06 05:29:32.797 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 5.13s
2025-10-06 05:29:32.798 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 94.85
2025-10-06 05:29:32.798 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:29:32.798 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:32.798 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:32.798 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:32.798 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:32.798 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:32.798 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:32.798 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:32.798 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:29:32.799 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:29:42.868 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:29:42.869 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.self_attn.q_proj using 256 samples
2025-10-06 05:29:44.233 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3583.07617
2025-10-06 05:29:44.234 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.49727e-02, min=1.24326e-02, max=1.76875e-01
2025-10-06 05:29:44.234 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:29:44.235 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3583.08
2025-10-06 05:29:44.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:29:44.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:44.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:44.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:44.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:44.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:44.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:44.235 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:44.235 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:29:44.236 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.self_attn.k_proj using 256 samples
2025-10-06 05:29:45.552 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2119.57520
2025-10-06 05:29:45.553 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.49727e-02, min=1.24326e-02, max=1.76875e-01
2025-10-06 05:29:45.553 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:29:45.553 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2119.58
2025-10-06 05:29:45.553 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:45.553 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:45.553 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:45.553 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:45.554 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:45.554 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:45.554 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:45.554 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:45.554 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:29:45.555 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.self_attn.v_proj using 256 samples
2025-10-06 05:29:46.871 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 258.15054
2025-10-06 05:29:46.871 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.49727e-02, min=1.24326e-02, max=1.76875e-01
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 258.15
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:46.872 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:29:46.873 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.self_attn.o_proj using 256 samples
2025-10-06 05:29:48.214 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 52.68810
2025-10-06 05:29:48.215 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.50179e-01, min=5.30475e-02, max=1.18673e+00
2025-10-06 05:29:48.215 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:29:48.215 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 52.69
2025-10-06 05:29:48.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:48.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:48.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:48.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:48.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:48.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:48.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:48.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:48.216 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:29:48.217 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.mlp.gate_proj using 256 samples
2025-10-06 05:29:49.629 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 5244.19824
2025-10-06 05:29:49.630 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.17091e-01, min=1.48079e-02, max=2.90512e-01
2025-10-06 05:29:49.630 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:29:49.630 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5244.20
2025-10-06 05:29:49.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:49.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:49.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:49.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:49.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:49.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:49.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:49.631 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:49.631 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:29:49.632 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.mlp.up_proj using 256 samples
2025-10-06 05:29:51.049 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 3969.04883
2025-10-06 05:29:51.050 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.17091e-01, min=1.48079e-02, max=2.90512e-01
2025-10-06 05:29:51.050 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:29:51.050 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3969.05
2025-10-06 05:29:51.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:29:51.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:51.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:51.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:51.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:51.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:51.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:51.051 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:51.051 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:29:51.052 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.14.mlp.down_proj using 256 samples
2025-10-06 05:29:55.954 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 124.67355
2025-10-06 05:29:55.957 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.97681e-01, min=7.63672e-02, max=1.41515e+00
2025-10-06 05:29:55.957 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.90s
2025-10-06 05:29:55.957 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 124.67
2025-10-06 05:29:55.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:29:55.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:55.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:55.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:55.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:55.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:55.957 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:55.958 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:29:55.958 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:29:55.958 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:30:06.165 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:30:06.165 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.self_attn.q_proj using 256 samples
2025-10-06 05:30:07.534 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4118.69824
2025-10-06 05:30:07.534 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.63970e-02, min=1.28565e-02, max=1.97534e-01
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4118.70
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:07.535 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:30:07.536 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.self_attn.k_proj using 256 samples
2025-10-06 05:30:08.853 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1996.56287
2025-10-06 05:30:08.854 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.63970e-02, min=1.28565e-02, max=1.97534e-01
2025-10-06 05:30:08.854 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:30:08.854 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1996.56
2025-10-06 05:30:08.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:08.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:08.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:08.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:08.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:08.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:08.854 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:08.855 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:08.855 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:30:08.855 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.self_attn.v_proj using 256 samples
2025-10-06 05:30:10.171 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 288.06537
2025-10-06 05:30:10.172 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.63970e-02, min=1.28565e-02, max=1.97534e-01
2025-10-06 05:30:10.172 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:30:10.173 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 288.07
2025-10-06 05:30:10.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:10.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:10.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:10.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:10.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:10.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:10.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:10.173 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:10.173 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:30:10.174 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.self_attn.o_proj using 256 samples
2025-10-06 05:30:11.520 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 38.70037
2025-10-06 05:30:11.521 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.01182e-01, min=9.08312e-02, max=1.07831e+00
2025-10-06 05:30:11.521 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:30:11.521 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 38.70
2025-10-06 05:30:11.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:11.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:11.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:11.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:11.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:11.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:11.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:11.522 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:11.522 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:30:11.523 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.mlp.gate_proj using 256 samples
2025-10-06 05:30:12.930 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 5672.91602
2025-10-06 05:30:12.931 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.14854e-01, min=1.60816e-02, max=3.16023e-01
2025-10-06 05:30:12.931 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:30:12.931 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5672.92
2025-10-06 05:30:12.931 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:12.931 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:12.931 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:12.931 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:12.931 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:12.931 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:12.931 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:12.932 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:12.932 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:30:12.932 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.mlp.up_proj using 256 samples
2025-10-06 05:30:14.345 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4085.27686
2025-10-06 05:30:14.346 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.14854e-01, min=1.60816e-02, max=3.16023e-01
2025-10-06 05:30:14.346 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:30:14.346 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4085.28
2025-10-06 05:30:14.346 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:14.346 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:14.346 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:14.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:14.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:14.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:14.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:14.347 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:14.347 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:30:14.348 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.15.mlp.down_proj using 256 samples
2025-10-06 05:30:19.248 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 130.94817
2025-10-06 05:30:19.250 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.87416e-01, min=9.12587e-02, max=1.17851e+00
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.90s
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 130.95
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:19.251 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:30:19.252 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:30:29.364 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:30:29.364 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.self_attn.q_proj using 256 samples
2025-10-06 05:30:30.739 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3680.02246
2025-10-06 05:30:30.740 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.00428e-01, min=1.19862e-02, max=1.98491e-01
2025-10-06 05:30:30.740 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:30:30.740 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3680.02
2025-10-06 05:30:30.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:30:30.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:30.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:30.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:30.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:30.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:30.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:30.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:30.741 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:30:30.742 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.self_attn.k_proj using 256 samples
2025-10-06 05:30:32.059 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1970.54980
2025-10-06 05:30:32.060 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.00428e-01, min=1.19862e-02, max=1.98491e-01
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1970.55
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:32.060 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:30:32.061 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.self_attn.v_proj using 256 samples
2025-10-06 05:30:33.377 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 262.51913
2025-10-06 05:30:33.378 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.00428e-01, min=1.19862e-02, max=1.98491e-01
2025-10-06 05:30:33.378 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:30:33.378 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 262.52
2025-10-06 05:30:33.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:33.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:33.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:33.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:33.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:33.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:33.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:33.379 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:33.379 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:30:33.380 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.self_attn.o_proj using 256 samples
2025-10-06 05:30:34.718 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 39.31425
2025-10-06 05:30:34.719 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.59263e-01, min=4.93326e-02, max=1.30879e+00
2025-10-06 05:30:34.719 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:30:34.720 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 39.31
2025-10-06 05:30:34.720 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:34.720 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:34.720 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:34.720 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:34.720 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:34.720 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:34.720 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:34.720 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:34.720 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:30:34.721 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.mlp.gate_proj using 256 samples
2025-10-06 05:30:36.133 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6181.13379
2025-10-06 05:30:36.134 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.11946e-01, min=1.86172e-02, max=2.90744e-01
2025-10-06 05:30:36.135 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:30:36.135 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6181.13
2025-10-06 05:30:36.136 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:36.136 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:36.136 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:36.136 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:36.136 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:36.136 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:36.136 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:36.136 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:36.136 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:30:36.137 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.mlp.up_proj using 256 samples
2025-10-06 05:30:37.547 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4210.43359
2025-10-06 05:30:37.548 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.11946e-01, min=1.86172e-02, max=2.90744e-01
2025-10-06 05:30:37.548 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:30:37.548 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4210.43
2025-10-06 05:30:37.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:37.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:37.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:37.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:37.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:37.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:37.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:37.548 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:37.549 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:30:37.549 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.16.mlp.down_proj using 256 samples
2025-10-06 05:30:42.426 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 148.08047
2025-10-06 05:30:42.429 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.31465e-01, min=4.58979e-02, max=1.01017e+00
2025-10-06 05:30:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.88s
2025-10-06 05:30:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 148.08
2025-10-06 05:30:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:30:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:42.429 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:42.430 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:30:42.431 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:30:52.379 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:30:52.380 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.self_attn.q_proj using 256 samples
2025-10-06 05:30:53.739 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3698.28418
2025-10-06 05:30:53.740 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.97694e-02, min=1.17675e-02, max=1.95646e-01
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.36s
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3698.28
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:53.741 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:30:53.742 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.self_attn.k_proj using 256 samples
2025-10-06 05:30:55.053 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1968.43933
2025-10-06 05:30:55.054 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.97694e-02, min=1.17675e-02, max=1.95646e-01
2025-10-06 05:30:55.054 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:30:55.054 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1968.44
2025-10-06 05:30:55.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:55.060 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:55.061 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:55.061 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:55.061 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:55.061 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:55.061 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:55.061 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:55.061 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:30:55.062 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.self_attn.v_proj using 256 samples
2025-10-06 05:30:56.370 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 293.98608
2025-10-06 05:30:56.371 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.97694e-02, min=1.17675e-02, max=1.95646e-01
2025-10-06 05:30:56.371 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:30:56.371 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 293.99
2025-10-06 05:30:56.371 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:56.371 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:56.371 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:56.371 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:56.371 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:56.371 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:56.372 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:56.372 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:56.372 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:30:56.372 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.self_attn.o_proj using 256 samples
2025-10-06 05:30:57.709 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 31.11656
2025-10-06 05:30:57.710 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.48853e-01, min=1.27295e-01, max=1.84125e+00
2025-10-06 05:30:57.710 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:30:57.710 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 31.12
2025-10-06 05:30:57.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:57.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:57.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:57.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:57.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:57.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:57.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:57.711 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:57.711 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:30:57.712 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.mlp.gate_proj using 256 samples
2025-10-06 05:30:59.116 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6186.44971
2025-10-06 05:30:59.117 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.12544e-01, min=2.10979e-02, max=3.30168e-01
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6186.45
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:30:59.118 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:30:59.119 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.mlp.up_proj using 256 samples
2025-10-06 05:31:00.529 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4128.55664
2025-10-06 05:31:00.530 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.12544e-01, min=2.10979e-02, max=3.30168e-01
2025-10-06 05:31:00.530 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:31:00.530 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4128.56
2025-10-06 05:31:00.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:00.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:00.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:00.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:00.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:00.530 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:00.531 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:00.531 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:00.531 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:31:00.532 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.17.mlp.down_proj using 256 samples
2025-10-06 05:31:05.438 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 147.91153
2025-10-06 05:31:05.441 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.40371e-01, min=4.79547e-02, max=1.23073e+00
2025-10-06 05:31:05.441 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.91s
2025-10-06 05:31:05.441 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 147.91
2025-10-06 05:31:05.442 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:31:05.442 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:05.442 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:05.442 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:05.442 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:05.442 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:05.442 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:05.442 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:05.442 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:31:05.443 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:31:15.591 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:31:15.591 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.self_attn.q_proj using 256 samples
2025-10-06 05:31:16.970 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3707.48682
2025-10-06 05:31:16.971 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.86160e-02, min=1.15913e-02, max=2.24469e-01
2025-10-06 05:31:16.971 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:31:16.971 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3707.49
2025-10-06 05:31:16.972 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:31:16.972 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:16.972 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:16.972 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:16.972 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:16.972 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:16.972 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:16.972 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:16.972 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:31:16.973 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.self_attn.k_proj using 256 samples
2025-10-06 05:31:18.291 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2129.48340
2025-10-06 05:31:18.292 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.86160e-02, min=1.15913e-02, max=2.24469e-01
2025-10-06 05:31:18.292 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:31:18.292 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2129.48
2025-10-06 05:31:18.292 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:18.292 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:18.292 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:18.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:18.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:18.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:18.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:18.293 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:18.293 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:31:18.294 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.self_attn.v_proj using 256 samples
2025-10-06 05:31:19.610 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 272.97327
2025-10-06 05:31:19.611 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.86160e-02, min=1.15913e-02, max=2.24469e-01
2025-10-06 05:31:19.611 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:31:19.611 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 272.97
2025-10-06 05:31:19.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:19.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:19.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:19.612 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:19.612 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:19.612 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:19.612 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:19.612 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:19.612 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:31:19.613 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.self_attn.o_proj using 256 samples
2025-10-06 05:31:20.960 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 22.17653
2025-10-06 05:31:20.961 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.00767e+00, min=1.21383e-01, max=2.74066e+00
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 22.18
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:20.961 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:31:20.962 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.mlp.gate_proj using 256 samples
2025-10-06 05:31:22.382 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6396.90771
2025-10-06 05:31:22.383 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.10607e-01, min=2.43925e-02, max=2.72316e-01
2025-10-06 05:31:22.383 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:31:22.383 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6396.91
2025-10-06 05:31:22.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:22.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:22.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:22.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:22.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:22.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:22.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:22.384 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:22.384 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:31:22.385 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.mlp.up_proj using 256 samples
2025-10-06 05:31:23.807 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4230.10059
2025-10-06 05:31:23.808 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.10607e-01, min=2.43925e-02, max=2.72316e-01
2025-10-06 05:31:23.808 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:31:23.808 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4230.10
2025-10-06 05:31:23.808 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:23.808 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:23.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:23.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:23.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:23.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:23.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:23.809 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:23.809 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:31:23.810 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.18.mlp.down_proj using 256 samples
2025-10-06 05:31:28.762 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 149.74345
2025-10-06 05:31:28.765 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.27635e-01, min=5.84942e-02, max=1.49680e+00
2025-10-06 05:31:28.765 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.96s
2025-10-06 05:31:28.765 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 149.74
2025-10-06 05:31:28.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:31:28.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:28.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:28.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:28.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:28.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:28.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:28.766 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:28.766 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:31:28.767 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:31:38.851 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:31:38.851 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.self_attn.q_proj using 256 samples
2025-10-06 05:31:40.224 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3820.56128
2025-10-06 05:31:40.225 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.67819e-02, min=1.34028e-02, max=1.94392e-01
2025-10-06 05:31:40.225 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:31:40.225 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3820.56
2025-10-06 05:31:40.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:31:40.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:40.225 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:40.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:40.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:40.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:40.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:40.226 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:40.226 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:31:40.227 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.self_attn.k_proj using 256 samples
2025-10-06 05:31:41.541 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2008.43604
2025-10-06 05:31:41.542 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.67819e-02, min=1.34028e-02, max=1.94392e-01
2025-10-06 05:31:41.542 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:31:41.543 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2008.44
2025-10-06 05:31:41.545 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:41.545 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:41.545 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:41.545 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:41.545 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:41.545 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:41.545 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:41.545 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:41.545 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:31:41.546 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.self_attn.v_proj using 256 samples
2025-10-06 05:31:42.859 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 304.79883
2025-10-06 05:31:42.860 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.67819e-02, min=1.34028e-02, max=1.94392e-01
2025-10-06 05:31:42.860 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:31:42.860 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 304.80
2025-10-06 05:31:42.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:42.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:42.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:42.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:42.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:42.872 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:42.873 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:42.873 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:42.873 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:31:42.874 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.self_attn.o_proj using 256 samples
2025-10-06 05:31:44.214 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 19.52703
2025-10-06 05:31:44.215 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.08919e+00, min=2.11200e-01, max=2.76418e+00
2025-10-06 05:31:44.215 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:31:44.216 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 19.53
2025-10-06 05:31:44.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:44.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:44.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:44.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:44.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:44.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:44.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:44.216 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:44.216 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:31:44.217 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.mlp.gate_proj using 256 samples
2025-10-06 05:31:45.623 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6918.14697
2025-10-06 05:31:45.624 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.06779e-01, min=2.50245e-02, max=3.14489e-01
2025-10-06 05:31:45.624 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:31:45.624 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6918.15
2025-10-06 05:31:45.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:45.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:45.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:45.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:45.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:45.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:45.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:45.625 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:45.625 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:31:45.626 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.mlp.up_proj using 256 samples
2025-10-06 05:31:47.036 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 4512.57471
2025-10-06 05:31:47.037 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.06779e-01, min=2.50245e-02, max=3.14489e-01
2025-10-06 05:31:47.037 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:31:47.037 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4512.57
2025-10-06 05:31:47.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:31:47.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:47.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:47.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:47.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:47.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:47.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:47.038 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:47.038 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:31:47.039 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.19.mlp.down_proj using 256 samples
2025-10-06 05:31:51.933 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 167.81290
2025-10-06 05:31:51.936 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.91404e-01, min=4.13280e-02, max=1.44177e+00
2025-10-06 05:31:51.936 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.90s
2025-10-06 05:31:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 167.81
2025-10-06 05:31:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:31:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:31:51.937 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:31:51.938 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:32:02.091 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:32:02.091 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.self_attn.q_proj using 256 samples
2025-10-06 05:32:03.466 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4009.91821
2025-10-06 05:32:03.467 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.47554e-02, min=1.23922e-02, max=2.01415e-01
2025-10-06 05:32:03.467 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:32:03.467 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4009.92
2025-10-06 05:32:03.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:32:03.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:03.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:03.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:03.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:03.467 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:03.468 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:03.468 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:03.468 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:32:03.468 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.self_attn.k_proj using 256 samples
2025-10-06 05:32:04.784 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2107.71729
2025-10-06 05:32:04.785 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.47554e-02, min=1.23922e-02, max=2.01415e-01
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2107.72
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:04.785 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:32:04.786 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.self_attn.v_proj using 256 samples
2025-10-06 05:32:06.100 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 360.61697
2025-10-06 05:32:06.101 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.47554e-02, min=1.23922e-02, max=2.01415e-01
2025-10-06 05:32:06.101 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:32:06.101 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 360.62
2025-10-06 05:32:06.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:06.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:06.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:06.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:06.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:06.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:06.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:06.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:06.102 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:32:06.103 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.self_attn.o_proj using 256 samples
2025-10-06 05:32:07.446 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 31.69242
2025-10-06 05:32:07.447 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.91877e-01, min=1.39118e-01, max=2.15488e+00
2025-10-06 05:32:07.447 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:32:07.447 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 31.69
2025-10-06 05:32:07.448 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:07.448 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:07.448 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:07.448 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:07.448 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:07.448 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:07.448 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:07.448 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:07.448 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:32:07.449 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.mlp.gate_proj using 256 samples
2025-10-06 05:32:08.862 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 7641.58057
2025-10-06 05:32:08.863 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01486e-01, min=2.62721e-02, max=3.07398e-01
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7641.58
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:08.864 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:32:08.865 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.mlp.up_proj using 256 samples
2025-10-06 05:32:10.279 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 5016.00293
2025-10-06 05:32:10.280 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=1.01486e-01, min=2.62721e-02, max=3.07398e-01
2025-10-06 05:32:10.280 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:32:10.280 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5016.00
2025-10-06 05:32:10.281 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:10.281 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:10.281 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:10.281 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:10.281 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:10.281 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:10.281 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:10.281 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:10.281 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:32:10.282 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.20.mlp.down_proj using 256 samples
2025-10-06 05:32:15.181 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 198.99449
2025-10-06 05:32:15.184 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.40581e-01, min=6.80699e-02, max=1.19034e+00
2025-10-06 05:32:15.184 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.90s
2025-10-06 05:32:15.184 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 198.99
2025-10-06 05:32:15.184 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:32:15.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:15.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:15.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:15.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:15.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:15.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:15.185 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:15.185 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:32:15.186 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:32:25.467 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:32:25.468 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.self_attn.q_proj using 256 samples
2025-10-06 05:32:26.844 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4123.03809
2025-10-06 05:32:26.845 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.25323e-02, min=1.25053e-02, max=1.92240e-01
2025-10-06 05:32:26.845 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:32:26.845 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4123.04
2025-10-06 05:32:26.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:32:26.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:26.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:26.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:26.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:26.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:26.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:26.845 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:26.846 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:32:26.846 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.self_attn.k_proj using 256 samples
2025-10-06 05:32:28.168 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2245.33887
2025-10-06 05:32:28.169 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.25323e-02, min=1.25053e-02, max=1.92240e-01
2025-10-06 05:32:28.169 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:32:28.169 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2245.34
2025-10-06 05:32:28.169 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:28.169 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:28.169 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:28.169 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:28.169 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:28.169 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:28.169 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:28.169 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:28.170 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:32:28.170 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.self_attn.v_proj using 256 samples
2025-10-06 05:32:29.488 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 384.44482
2025-10-06 05:32:29.489 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.25323e-02, min=1.25053e-02, max=1.92240e-01
2025-10-06 05:32:29.489 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:32:29.489 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 384.44
2025-10-06 05:32:29.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:29.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:29.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:29.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:29.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:29.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:29.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:29.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:29.490 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:32:29.491 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.self_attn.o_proj using 256 samples
2025-10-06 05:32:30.841 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 29.21378
2025-10-06 05:32:30.842 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.64681e-01, min=9.78212e-02, max=1.90496e+00
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 29.21
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:30.842 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:32:30.843 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.mlp.gate_proj using 256 samples
2025-10-06 05:32:32.253 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 8565.83105
2025-10-06 05:32:32.254 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.62747e-02, min=2.71250e-02, max=2.80520e-01
2025-10-06 05:32:32.254 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:32:32.254 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8565.83
2025-10-06 05:32:32.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:32.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:32.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:32.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:32.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:32.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:32.254 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:32.255 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:32.255 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:32:32.255 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.mlp.up_proj using 256 samples
2025-10-06 05:32:33.667 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 5592.00488
2025-10-06 05:32:33.668 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.62747e-02, min=2.71250e-02, max=2.80520e-01
2025-10-06 05:32:33.668 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:32:33.668 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5592.00
2025-10-06 05:32:33.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:33.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:33.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:33.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:33.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:33.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:33.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:33.669 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:33.669 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:32:33.670 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.21.mlp.down_proj using 256 samples
2025-10-06 05:32:38.577 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 237.41660
2025-10-06 05:32:38.580 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=5.00081e-01, min=4.24362e-02, max=8.31619e-01
2025-10-06 05:32:38.580 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.91s
2025-10-06 05:32:38.580 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 237.42
2025-10-06 05:32:38.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:32:38.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:38.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:38.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:38.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:38.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:38.580 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:38.581 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:38.581 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:32:38.581 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:32:48.567 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:32:48.567 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.self_attn.q_proj using 256 samples
2025-10-06 05:32:49.947 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4217.59082
2025-10-06 05:32:49.947 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.89195e-02, min=1.26510e-02, max=1.99372e-01
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4217.59
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:49.948 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:32:49.949 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.self_attn.k_proj using 256 samples
2025-10-06 05:32:51.267 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2299.79565
2025-10-06 05:32:51.268 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.89195e-02, min=1.26510e-02, max=1.99372e-01
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2299.80
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:51.269 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:32:51.270 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.self_attn.v_proj using 256 samples
2025-10-06 05:32:52.585 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 474.23013
2025-10-06 05:32:52.586 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.89195e-02, min=1.26510e-02, max=1.99372e-01
2025-10-06 05:32:52.586 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:32:52.586 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 474.23
2025-10-06 05:32:52.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:52.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:52.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:52.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:52.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:52.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:52.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:52.587 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:52.587 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:32:52.588 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.self_attn.o_proj using 256 samples
2025-10-06 05:32:53.932 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 34.96642
2025-10-06 05:32:53.933 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.45940e-01, min=1.47290e-01, max=2.46539e+00
2025-10-06 05:32:53.933 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:32:53.933 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 34.97
2025-10-06 05:32:53.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:53.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:53.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:53.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:53.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:53.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:53.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:53.934 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:53.934 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:32:53.935 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.mlp.gate_proj using 256 samples
2025-10-06 05:32:55.350 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 9339.98047
2025-10-06 05:32:55.351 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.23110e-02, min=2.76938e-02, max=3.02797e-01
2025-10-06 05:32:55.351 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:32:55.351 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 9339.98
2025-10-06 05:32:55.351 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:55.351 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:55.351 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:55.351 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:55.352 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:55.352 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:55.352 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:55.352 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:55.352 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:32:55.353 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.mlp.up_proj using 256 samples
2025-10-06 05:32:56.772 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6151.82227
2025-10-06 05:32:56.773 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.23110e-02, min=2.76938e-02, max=3.02797e-01
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6151.82
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:32:56.774 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:32:56.775 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.22.mlp.down_proj using 256 samples
2025-10-06 05:33:01.675 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 260.96078
2025-10-06 05:33:01.678 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.72137e-01, min=5.69452e-02, max=8.35445e-01
2025-10-06 05:33:01.678 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.90s
2025-10-06 05:33:01.678 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 260.96
2025-10-06 05:33:01.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:33:01.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:01.738 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:01.738 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:01.738 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:01.738 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:01.738 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:01.738 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:01.738 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:33:01.739 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:33:11.821 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:33:11.821 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.self_attn.q_proj using 256 samples
2025-10-06 05:33:13.195 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4475.64941
2025-10-06 05:33:13.196 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.47727e-02, min=1.36880e-02, max=2.13143e-01
2025-10-06 05:33:13.196 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:33:13.196 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4475.65
2025-10-06 05:33:13.197 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:33:13.197 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:13.197 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:13.197 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:13.197 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:13.197 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:13.197 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:13.197 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:13.197 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:33:13.198 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.self_attn.k_proj using 256 samples
2025-10-06 05:33:14.516 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2364.47192
2025-10-06 05:33:14.517 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.47727e-02, min=1.36880e-02, max=2.13143e-01
2025-10-06 05:33:14.517 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:33:14.517 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2364.47
2025-10-06 05:33:14.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:33:14.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:14.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:14.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:14.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:14.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:14.517 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:14.518 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:14.518 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:33:14.518 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.self_attn.v_proj using 256 samples
2025-10-06 05:33:15.834 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 542.94635
2025-10-06 05:33:15.835 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.47727e-02, min=1.36880e-02, max=2.13143e-01
2025-10-06 05:33:15.835 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:33:15.835 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 542.95
2025-10-06 05:33:15.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:33:15.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:15.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:15.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:15.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:15.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:15.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:15.836 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:15.836 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:33:15.837 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.self_attn.o_proj using 256 samples
2025-10-06 05:33:17.180 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 26.29206
2025-10-06 05:33:17.181 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.98470e-01, min=1.33420e-01, max=2.13406e+00
2025-10-06 05:33:17.181 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:33:17.181 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 26.29
2025-10-06 05:33:17.181 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:33:17.181 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:17.181 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:17.181 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:17.181 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:17.181 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:17.182 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:17.182 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:17.182 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:33:17.182 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.mlp.gate_proj using 256 samples
2025-10-06 05:33:18.594 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 10453.61230
2025-10-06 05:33:18.595 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.72256e-02, min=2.94678e-02, max=2.63059e-01
2025-10-06 05:33:18.595 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:33:18.595 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 10453.61
2025-10-06 05:33:18.596 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:33:18.596 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:18.596 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:18.596 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:18.596 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:18.596 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:18.596 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:18.596 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:18.596 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:33:18.597 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.mlp.up_proj using 256 samples
2025-10-06 05:33:20.008 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 6925.94824
2025-10-06 05:33:20.009 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.72256e-02, min=2.94678e-02, max=2.63059e-01
2025-10-06 05:33:20.009 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:33:20.009 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 6925.95
2025-10-06 05:33:20.009 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:33:20.009 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:20.010 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:20.010 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:20.010 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:20.010 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:20.010 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:20.010 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:20.010 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:33:20.011 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.23.mlp.down_proj using 256 samples
2025-10-06 05:33:24.914 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 314.36060
2025-10-06 05:33:24.917 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.32599e-01, min=6.25226e-02, max=7.02526e-01
2025-10-06 05:33:24.917 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.91s
2025-10-06 05:33:24.918 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 314.36
2025-10-06 05:33:24.918 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:33:24.918 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:24.918 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:24.918 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:24.918 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:24.918 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:24.918 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:24.918 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:24.918 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:33:24.919 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:33:35.064 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:33:35.064 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.self_attn.q_proj using 256 samples
2025-10-06 05:33:36.443 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4501.47607
2025-10-06 05:33:36.444 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.33365e-02, min=1.37478e-02, max=2.14251e-01
2025-10-06 05:33:36.444 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:33:36.444 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4501.48
2025-10-06 05:33:36.445 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:33:36.445 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:36.445 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:36.445 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:36.445 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:36.445 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:36.445 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:36.445 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:36.445 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:33:36.446 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.self_attn.k_proj using 256 samples
2025-10-06 05:33:37.766 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2243.37695
2025-10-06 05:33:37.767 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.33365e-02, min=1.37478e-02, max=2.14251e-01
2025-10-06 05:33:37.767 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:33:37.767 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2243.38
2025-10-06 05:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:37.768 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:33:37.769 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.self_attn.v_proj using 256 samples
2025-10-06 05:33:39.087 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 651.85144
2025-10-06 05:33:39.087 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.33365e-02, min=1.37478e-02, max=2.14251e-01
2025-10-06 05:33:39.087 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:33:39.088 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 651.85
2025-10-06 05:33:39.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:33:39.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:39.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:39.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:39.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:39.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:39.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:39.088 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:39.088 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:33:39.089 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.self_attn.o_proj using 256 samples
2025-10-06 05:33:40.433 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 38.98625
2025-10-06 05:33:40.434 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.83056e-01, min=8.92594e-02, max=1.58188e+00
2025-10-06 05:33:40.434 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:33:40.434 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 38.99
2025-10-06 05:33:40.434 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:33:40.434 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:40.435 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:40.435 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:40.435 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:40.435 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:40.435 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:40.435 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:40.435 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:33:40.436 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.mlp.gate_proj using 256 samples
2025-10-06 05:33:41.854 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 11567.47656
2025-10-06 05:33:41.855 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.31806e-02, min=2.91631e-02, max=2.82666e-01
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11567.48
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:41.856 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:33:41.857 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.mlp.up_proj using 256 samples
2025-10-06 05:33:43.268 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 7641.49463
2025-10-06 05:33:43.269 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.31806e-02, min=2.91631e-02, max=2.82666e-01
2025-10-06 05:33:43.269 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:33:43.269 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 7641.49
2025-10-06 05:33:43.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:33:43.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:43.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:43.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:43.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:43.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:43.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:43.270 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:43.270 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:33:43.271 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.24.mlp.down_proj using 256 samples
2025-10-06 05:33:48.171 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 369.61530
2025-10-06 05:33:48.174 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.99458e-01, min=5.90357e-02, max=6.10241e-01
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.90s
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 369.62
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:48.175 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:33:48.176 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:33:58.282 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:33:58.283 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.self_attn.q_proj using 256 samples
2025-10-06 05:33:59.663 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4717.09326
2025-10-06 05:33:59.664 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.92901e-02, min=1.52645e-02, max=2.05541e-01
2025-10-06 05:33:59.664 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:33:59.664 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4717.09
2025-10-06 05:33:59.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:33:59.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:59.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:59.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:59.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:59.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:59.664 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:59.665 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:33:59.665 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:33:59.665 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.self_attn.k_proj using 256 samples
2025-10-06 05:34:00.985 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2351.79004
2025-10-06 05:34:00.986 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.92901e-02, min=1.52645e-02, max=2.05541e-01
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2351.79
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:00.986 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:34:00.987 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.self_attn.v_proj using 256 samples
2025-10-06 05:34:02.302 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 719.91296
2025-10-06 05:34:02.303 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.92901e-02, min=1.52645e-02, max=2.05541e-01
2025-10-06 05:34:02.303 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:34:02.303 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 719.91
2025-10-06 05:34:02.304 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:02.304 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:02.304 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:02.304 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:02.304 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:02.304 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:02.304 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:02.304 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:02.304 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:34:02.305 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.self_attn.o_proj using 256 samples
2025-10-06 05:34:03.651 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 40.70975
2025-10-06 05:34:03.652 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.22579e-01, min=9.32743e-02, max=1.53447e+00
2025-10-06 05:34:03.652 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:34:03.652 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 40.71
2025-10-06 05:34:03.652 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:03.652 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:03.652 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:03.652 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:03.652 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:03.653 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:03.653 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:03.653 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:03.653 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:34:03.653 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.mlp.gate_proj using 256 samples
2025-10-06 05:34:05.065 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 13024.06934
2025-10-06 05:34:05.066 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.86966e-02, min=2.91176e-02, max=2.66281e-01
2025-10-06 05:34:05.066 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:34:05.066 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 13024.07
2025-10-06 05:34:05.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:05.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:05.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:05.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:05.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:05.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:05.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:05.067 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:05.067 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:34:05.068 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.mlp.up_proj using 256 samples
2025-10-06 05:34:06.483 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 8580.67383
2025-10-06 05:34:06.484 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.86966e-02, min=2.91176e-02, max=2.66281e-01
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 8580.67
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:06.484 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:34:06.485 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.25.mlp.down_proj using 256 samples
2025-10-06 05:34:11.466 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 453.49231
2025-10-06 05:34:11.468 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.64732e-01, min=2.20191e-02, max=6.65426e-01
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.98s
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 453.49
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:11.469 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:34:11.470 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:34:21.589 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:34:21.589 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.self_attn.q_proj using 256 samples
2025-10-06 05:34:22.967 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4593.17920
2025-10-06 05:34:22.968 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.16083e-02, min=1.34256e-02, max=2.03219e-01
2025-10-06 05:34:22.968 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.38s
2025-10-06 05:34:22.968 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4593.18
2025-10-06 05:34:22.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:34:22.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:22.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:22.968 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:22.969 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:22.969 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:22.969 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:22.969 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:22.969 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:34:22.970 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.self_attn.k_proj using 256 samples
2025-10-06 05:34:24.288 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2434.01758
2025-10-06 05:34:24.289 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.16083e-02, min=1.34256e-02, max=2.03219e-01
2025-10-06 05:34:24.289 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:34:24.290 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2434.02
2025-10-06 05:34:24.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:24.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:24.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:24.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:24.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:24.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:24.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:24.290 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:24.290 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:34:24.291 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.self_attn.v_proj using 256 samples
2025-10-06 05:34:25.609 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 709.99609
2025-10-06 05:34:25.610 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.16083e-02, min=1.34256e-02, max=2.03219e-01
2025-10-06 05:34:25.610 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:34:25.610 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 710.00
2025-10-06 05:34:25.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:25.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:25.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:25.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:25.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:25.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:25.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:25.611 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:25.611 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:34:25.612 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.self_attn.o_proj using 256 samples
2025-10-06 05:34:26.957 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 53.06485
2025-10-06 05:34:26.958 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.55104e-01, min=9.40373e-02, max=1.60892e+00
2025-10-06 05:34:26.958 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:34:26.958 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 53.06
2025-10-06 05:34:26.958 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:26.958 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:26.959 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:26.959 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:26.959 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:26.959 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:26.959 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:26.959 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:26.959 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:34:26.960 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.mlp.gate_proj using 256 samples
2025-10-06 05:34:28.382 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 14236.82031
2025-10-06 05:34:28.383 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.54381e-02, min=2.60692e-02, max=2.57367e-01
2025-10-06 05:34:28.383 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:34:28.383 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 14236.82
2025-10-06 05:34:28.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:28.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:28.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:28.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:28.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:28.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:28.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:28.383 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:28.384 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:34:28.384 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.mlp.up_proj using 256 samples
2025-10-06 05:34:29.805 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 9363.79395
2025-10-06 05:34:29.806 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.54381e-02, min=2.60692e-02, max=2.57367e-01
2025-10-06 05:34:29.807 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:34:29.807 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 9363.79
2025-10-06 05:34:29.812 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:29.812 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:29.812 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:29.812 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:29.812 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:29.812 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:29.813 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:29.813 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:29.813 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:34:29.814 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.26.mlp.down_proj using 256 samples
2025-10-06 05:34:34.734 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 529.55579
2025-10-06 05:34:34.736 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.41730e-01, min=3.85922e-02, max=7.83169e-01
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.92s
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 529.56
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:34.737 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:34:34.738 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:34:45.012 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:34:45.012 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.self_attn.q_proj using 256 samples
2025-10-06 05:34:46.384 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 5005.51855
2025-10-06 05:34:46.385 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.55563e-02, min=1.55894e-02, max=2.89235e-01
2025-10-06 05:34:46.385 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:34:46.385 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 5005.52
2025-10-06 05:34:46.385 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:34:46.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:46.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:46.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:46.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:46.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:46.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:46.386 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:46.386 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:34:46.387 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.self_attn.k_proj using 256 samples
2025-10-06 05:34:47.709 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2679.45117
2025-10-06 05:34:47.710 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.55563e-02, min=1.55894e-02, max=2.89235e-01
2025-10-06 05:34:47.710 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:34:47.710 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2679.45
2025-10-06 05:34:47.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:47.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:47.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:47.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:47.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:47.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:47.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:47.710 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:47.711 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:34:47.711 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.self_attn.v_proj using 256 samples
2025-10-06 05:34:49.030 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 941.03430
2025-10-06 05:34:49.031 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.55563e-02, min=1.55894e-02, max=2.89235e-01
2025-10-06 05:34:49.031 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:34:49.031 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 941.03
2025-10-06 05:34:49.031 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:49.031 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:49.032 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:49.032 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:49.032 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:49.032 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:49.032 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:49.032 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:49.032 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:34:49.033 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.self_attn.o_proj using 256 samples
2025-10-06 05:34:50.379 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 75.68497
2025-10-06 05:34:50.380 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.99040e-01, min=3.28430e-02, max=1.65186e+00
2025-10-06 05:34:50.380 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:34:50.380 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 75.68
2025-10-06 05:34:50.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:50.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:50.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:50.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:50.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:50.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:50.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:50.381 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:50.381 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:34:50.382 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.mlp.gate_proj using 256 samples
2025-10-06 05:34:51.793 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 15941.45508
2025-10-06 05:34:51.794 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.16588e-02, min=2.65124e-02, max=2.32928e-01
2025-10-06 05:34:51.794 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:34:51.794 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 15941.46
2025-10-06 05:34:51.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:51.794 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:51.795 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:51.795 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:51.795 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:51.795 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:51.795 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:51.795 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:51.795 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:34:51.796 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.mlp.up_proj using 256 samples
2025-10-06 05:34:53.208 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 10445.23047
2025-10-06 05:34:53.209 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.16588e-02, min=2.65124e-02, max=2.32928e-01
2025-10-06 05:34:53.209 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:34:53.209 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 10445.23
2025-10-06 05:34:53.209 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:34:53.209 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:53.210 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:53.210 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:53.210 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:53.210 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:53.210 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:53.210 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:53.210 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:34:53.211 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.27.mlp.down_proj using 256 samples
2025-10-06 05:34:58.113 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 655.18103
2025-10-06 05:34:58.116 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.13776e-01, min=1.98831e-02, max=6.44147e-01
2025-10-06 05:34:58.116 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.91s
2025-10-06 05:34:58.116 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 655.18
2025-10-06 05:34:58.116 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:34:58.116 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:58.116 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:58.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:58.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:58.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:58.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:58.117 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:34:58.117 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:34:58.118 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:35:08.129 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:35:08.129 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.self_attn.q_proj using 256 samples
2025-10-06 05:35:09.502 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4828.78809
2025-10-06 05:35:09.503 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.62799e-02, min=1.59350e-02, max=1.83603e-01
2025-10-06 05:35:09.503 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:35:09.503 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4828.79
2025-10-06 05:35:09.503 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:35:09.504 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:09.504 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:09.504 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:09.504 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:09.504 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:09.504 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:09.504 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:09.504 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:35:09.505 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.self_attn.k_proj using 256 samples
2025-10-06 05:35:10.821 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2341.50146
2025-10-06 05:35:10.822 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.62799e-02, min=1.59350e-02, max=1.83603e-01
2025-10-06 05:35:10.822 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:35:10.822 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2341.50
2025-10-06 05:35:10.822 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:10.822 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:10.822 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:10.822 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:10.822 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:10.822 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:10.822 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:10.822 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:10.823 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:35:10.823 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.self_attn.v_proj using 256 samples
2025-10-06 05:35:12.139 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 958.10150
2025-10-06 05:35:12.139 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.62799e-02, min=1.59350e-02, max=1.83603e-01
2025-10-06 05:35:12.139 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:35:12.140 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 958.10
2025-10-06 05:35:12.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:12.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:12.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:12.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:12.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:12.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:12.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:12.140 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:12.140 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:35:12.141 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.self_attn.o_proj using 256 samples
2025-10-06 05:35:13.489 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 122.03626
2025-10-06 05:35:13.490 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.61505e-01, min=8.02622e-02, max=1.14450e+00
2025-10-06 05:35:13.490 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:35:13.490 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 122.04
2025-10-06 05:35:13.490 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:13.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:13.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:13.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:13.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:13.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:13.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:13.491 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:13.491 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:35:13.492 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.mlp.gate_proj using 256 samples
2025-10-06 05:35:14.904 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 16349.73633
2025-10-06 05:35:14.905 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.99245e-02, min=2.72009e-02, max=2.07428e-01
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 16349.74
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:14.905 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:35:14.906 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.mlp.up_proj using 256 samples
2025-10-06 05:35:16.322 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 11073.61719
2025-10-06 05:35:16.323 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.99245e-02, min=2.72009e-02, max=2.07428e-01
2025-10-06 05:35:16.323 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.42s
2025-10-06 05:35:16.324 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11073.62
2025-10-06 05:35:16.324 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:16.324 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:16.324 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:16.324 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:16.324 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:16.324 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:16.324 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:16.324 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:16.324 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:35:16.325 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.28.mlp.down_proj using 256 samples
2025-10-06 05:35:21.236 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 729.12073
2025-10-06 05:35:21.239 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.05402e-01, min=2.36696e-02, max=7.59577e-01
2025-10-06 05:35:21.239 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.91s
2025-10-06 05:35:21.239 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 729.12
2025-10-06 05:35:21.239 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:35:21.239 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:21.239 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:21.239 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:21.239 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:21.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:21.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:21.240 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:21.240 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:35:21.241 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:35:31.311 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:35:31.311 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.self_attn.q_proj using 256 samples
2025-10-06 05:35:32.684 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4965.27734
2025-10-06 05:35:32.685 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.31529e-02, min=1.62186e-02, max=2.74854e-01
2025-10-06 05:35:32.685 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:35:32.686 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4965.28
2025-10-06 05:35:32.686 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:35:32.686 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:32.686 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:32.686 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:32.686 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:32.686 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:32.686 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:32.686 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:32.686 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:35:32.687 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.self_attn.k_proj using 256 samples
2025-10-06 05:35:34.005 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 2647.41431
2025-10-06 05:35:34.005 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.31529e-02, min=1.62186e-02, max=2.74854e-01
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2647.41
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:34.006 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:35:34.007 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.self_attn.v_proj using 256 samples
2025-10-06 05:35:35.324 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1073.57556
2025-10-06 05:35:35.325 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.31529e-02, min=1.62186e-02, max=2.74854e-01
2025-10-06 05:35:35.325 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:35:35.325 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1073.58
2025-10-06 05:35:35.325 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:35.325 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:35.325 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:35.325 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:35.325 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:35.325 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:35.326 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:35.326 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:35.326 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:35:35.326 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.self_attn.o_proj using 256 samples
2025-10-06 05:35:36.673 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 98.50063
2025-10-06 05:35:36.674 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.53193e-01, min=5.76215e-02, max=1.27821e+00
2025-10-06 05:35:36.674 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.35s
2025-10-06 05:35:36.674 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 98.50
2025-10-06 05:35:36.678 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:36.679 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:36.679 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:36.679 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:36.679 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:36.679 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:36.679 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:36.679 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:36.679 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:35:36.680 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.mlp.gate_proj using 256 samples
2025-10-06 05:35:38.091 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 16523.69531
2025-10-06 05:35:38.092 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.92474e-02, min=2.04580e-02, max=1.88305e-01
2025-10-06 05:35:38.092 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:35:38.092 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 16523.70
2025-10-06 05:35:38.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:38.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:38.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:38.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:38.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:38.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:38.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:38.093 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:38.093 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:35:38.094 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.mlp.up_proj using 256 samples
2025-10-06 05:35:39.506 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 11591.63086
2025-10-06 05:35:39.507 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=6.92474e-02, min=2.04580e-02, max=1.88305e-01
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11591.63
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:39.508 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:35:39.509 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.29.mlp.down_proj using 256 samples
2025-10-06 05:35:44.421 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 863.28668
2025-10-06 05:35:44.425 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.89916e-01, min=2.30220e-02, max=7.03752e-01
2025-10-06 05:35:44.425 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.92s
2025-10-06 05:35:44.425 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 863.29
2025-10-06 05:35:44.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:35:44.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:44.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:44.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:44.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:44.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:44.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:44.425 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:44.426 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:35:44.427 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:35:54.413 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:35:54.413 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.self_attn.q_proj using 256 samples
2025-10-06 05:35:55.783 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 4276.37695
2025-10-06 05:35:55.784 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.94197e-02, min=1.63821e-02, max=1.89067e-01
2025-10-06 05:35:55.784 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:35:55.784 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 4276.38
2025-10-06 05:35:55.784 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:35:55.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:55.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:55.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:55.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:55.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:55.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:55.785 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:55.785 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:35:55.786 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.self_attn.k_proj using 256 samples
2025-10-06 05:35:57.100 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1938.97766
2025-10-06 05:35:57.101 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.94197e-02, min=1.63821e-02, max=1.89067e-01
2025-10-06 05:35:57.101 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:35:57.101 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1938.98
2025-10-06 05:35:57.101 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:57.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:57.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:57.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:57.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:57.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:57.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:57.102 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:57.102 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:35:57.103 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.self_attn.v_proj using 256 samples
2025-10-06 05:35:58.419 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1321.99438
2025-10-06 05:35:58.420 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.94197e-02, min=1.63821e-02, max=1.89067e-01
2025-10-06 05:35:58.420 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.32s
2025-10-06 05:35:58.420 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1321.99
2025-10-06 05:35:58.420 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:58.420 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:58.421 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:58.421 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:58.421 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:58.421 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:58.421 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:58.421 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:58.421 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:35:58.422 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.self_attn.o_proj using 256 samples
2025-10-06 05:35:59.759 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 222.46338
2025-10-06 05:35:59.760 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=3.88378e-01, min=5.20590e-02, max=1.12516e+00
2025-10-06 05:35:59.760 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:35:59.760 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 222.46
2025-10-06 05:35:59.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:35:59.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:59.760 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:59.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:59.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:59.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:59.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:59.761 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:35:59.761 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:35:59.762 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.mlp.gate_proj using 256 samples
2025-10-06 05:36:01.175 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 16902.99414
2025-10-06 05:36:01.176 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.05185e-02, min=2.39917e-02, max=1.87286e-01
2025-10-06 05:36:01.176 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:36:01.176 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 16902.99
2025-10-06 05:36:01.176 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:36:01.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:01.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:01.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:01.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:01.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:01.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:01.177 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:01.177 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:36:01.178 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.mlp.up_proj using 256 samples
2025-10-06 05:36:02.590 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 11399.46680
2025-10-06 05:36:02.591 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=7.05185e-02, min=2.39917e-02, max=1.87286e-01
2025-10-06 05:36:02.591 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:36:02.591 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 11399.47
2025-10-06 05:36:02.591 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:36:02.591 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:02.592 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:02.592 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:02.592 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:02.592 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:02.592 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:02.592 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:02.592 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:36:02.593 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.30.mlp.down_proj using 256 samples
2025-10-06 05:36:07.490 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 1056.20654
2025-10-06 05:36:07.493 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.77022e-01, min=2.08567e-02, max=7.00039e-01
2025-10-06 05:36:07.493 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.90s
2025-10-06 05:36:07.493 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1056.21
2025-10-06 05:36:07.497 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:36:07.497 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:07.497 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:07.497 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:07.497 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:07.497 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:07.497 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:07.497 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:07.497 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:36:07.498 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:36:17.524 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:36:17.524 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.self_attn.q_proj using 256 samples
2025-10-06 05:36:18.895 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 3353.51367
2025-10-06 05:36:18.896 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.49383e-02, min=2.34745e-02, max=2.64906e-01
2025-10-06 05:36:18.896 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.37s
2025-10-06 05:36:18.896 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 3353.51
2025-10-06 05:36:18.896 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.62% | total memory: 85 GB
2025-10-06 05:36:18.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:18.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:18.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:18.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:18.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:18.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:18.897 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:18.897 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:36:18.898 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.self_attn.k_proj using 256 samples
2025-10-06 05:36:20.210 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 1542.65686
2025-10-06 05:36:20.211 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.49383e-02, min=2.34745e-02, max=2.64906e-01
2025-10-06 05:36:20.211 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:36:20.211 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 1542.66
2025-10-06 05:36:20.211 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:36:20.211 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:20.211 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:20.211 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:20.211 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:20.211 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:20.212 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:20.212 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:20.212 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:36:20.212 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.self_attn.v_proj using 256 samples
2025-10-06 05:36:21.526 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=1024, bias=False
  (weight_observer): MinMaxObserver()
): 740.19751
2025-10-06 05:36:21.527 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=9.49383e-02, min=2.34745e-02, max=2.64906e-01
2025-10-06 05:36:21.527 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.31s
2025-10-06 05:36:21.527 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 740.20
2025-10-06 05:36:21.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:36:21.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:21.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:21.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:21.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:21.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:21.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:21.528 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:21.528 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 8.9129 MB
2025-10-06 05:36:21.529 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.self_attn.o_proj using 256 samples
2025-10-06 05:36:22.869 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 187.50461
2025-10-06 05:36:22.870 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=4.20681e-01, min=4.80861e-02, max=9.74557e-01
2025-10-06 05:36:22.870 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.34s
2025-10-06 05:36:22.870 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 187.50
2025-10-06 05:36:22.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:36:22.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:22.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:22.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:22.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:22.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:22.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:22.871 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:22.871 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 35.651588 MB
2025-10-06 05:36:22.872 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.mlp.gate_proj using 256 samples
2025-10-06 05:36:24.285 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 13465.99023
2025-10-06 05:36:24.286 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.88388e-02, min=1.84406e-02, max=3.15235e-01
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 13465.99
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:24.287 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:36:24.288 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.mlp.up_proj using 256 samples
2025-10-06 05:36:25.699 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=4096, out_features=14336, bias=False
  (weight_observer): MinMaxObserver()
): 9139.79199
2025-10-06 05:36:25.700 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=8.88388e-02, min=1.84406e-02, max=3.15235e-01
2025-10-06 05:36:25.700 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 1.41s
2025-10-06 05:36:25.700 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 9139.79
2025-10-06 05:36:25.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 5.63% | total memory: 85 GB
2025-10-06 05:36:25.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:25.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:25.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:25.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:25.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:25.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:25.701 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:25.701 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:36:25.702 | INFO     | llmcompressor.modifiers.quantization.gptq.base:compress_modules:258 - Quantizing model.layers.31.mlp.down_proj using 256 samples
2025-10-06 05:36:30.601 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:304 - GPTQ quantization loss for Linear(
  in_features=14336, out_features=4096, bias=False
  (weight_observer): MinMaxObserver()
): 2331.80591
2025-10-06 05:36:30.603 | INFO     | llmcompressor.modifiers.quantization.gptq.gptq_quantize:quantize_weight:305 - H diag mean=2.15765e-01, min=6.56132e-03, max=3.74590e-01
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:136 - time 4.90s
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:138 - error 2331.81
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 0 | usage: 7.55% | total memory: 85 GB
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 1 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 2 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 3 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 4 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 5 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 6 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:145 - GPU 7 | usage: 0.70% | total memory: 85 GB
2025-10-06 05:36:30.604 | METRIC   | llmcompressor.utils.metric_logging:compress:154 - Compressed module size: 124.780548 MB
2025-10-06 05:36:30.605 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:36:33.609 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.SEQUENTIAL_EPOCH_END
2025-10-06 05:36:33.609 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=False sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:36:35.135 | DEBUG    | llmcompressor.core.lifecycle:event:195 - Handling event: EventType.CALIBRATION_EPOCH_END
2025-10-06 05:36:35.140 | DEBUG    | llmcompressor.core.lifecycle:event:205 - Updated event with modifier: config_groups=None targets=['Linear'] ignore=['lm_head'] scheme='NVFP4A16' kv_cache_scheme=None index=None group=None start=None end=None update=None initialized_=True finalized_=False started_=True ended_=True sequential_targets=None block_size=128 dampening_frac=0.01 actorder=static offload_hessians=False
2025-10-06 05:36:35.142 | DEBUG    | llmcompressor.core.lifecycle:finalize:134 - Finalizing compression lifecycle
